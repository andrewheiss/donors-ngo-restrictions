---
title: "Models"
author: "Suparna Chaudhry and Andrew Heiss"
date: "`r format(Sys.time(), '%F')`"
output: 
  html_document:
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
# Externalize these chunks:
# http://zevross.com/blog/2014/07/09/making-use-of-external-r-code-in-knitr-and-r-markdown/
# Except @knitr was replaced with four dashes because of RStudio section folding
if (isTRUE(getOption('knitr.in.progress'))) {
  knitr::read_chunk(here::here("lib", "models-chunks.R"))
} else {
  source(here::here("lib", "models-chunks.R"))
}
```

```{r load-libraries, message=FALSE}
```

```{r load-data, cache=TRUE, message=FALSE}
```

```{r furrr, message=FALSE}
library(furrr)
plan(multiprocess)
```

```{r huxtable-functions}
# Print correct huxtable table depending on the type of output.
#
# Technically this isn't completely necessary, since huxtable can output a
# markdown table, which is ostensibly universal for all output types. However,
# markdown tables are inherently limited in how fancy they can be (e.g. they
# don't support column spans), so I instead let the regression table use
# huxtable's fancy formatting for html and PDF and markdown everywhere else.
if (isTRUE(getOption('knitr.in.progress'))) {
  file_format <- rmarkdown::all_output_formats(knitr::current_input())
} else {
  file_format <- ""
}

print_hux <- function(x) {
  if ("html_document" %in% file_format) {
    print_html(x)
  } else if ("pdf_document" %in% file_format) {
    print_latex(x)
  } else if ("word_document" %in% file_format) {
    print_md(x)
  } else {
    print(x)
  }
}
```

```{r helpful-functions}
```

## Dependent variables

As explained in each section below, we have to transform and operationalize the dependent variable (foreign aid) in different ways for each hypothesis. The table belows summarizes each simplified model specification.

$$
\begin{aligned}
\boldsymbol{H_1}&: ln( \text{ODA}_{\text{OECD}} )_{i, t+1} &= \text{NGO legislation}_{it} + \text{controls}_{it} \\
\boldsymbol{H_2}&: ln( \frac{\text{contentious ODA}_{\text{OECD}}}{\text{noncontentious ODA}_{\text{OECD}}} )_{i, t+1} &= \text{NGO legislation}_{it} + \text{controls}_{it} \\
\boldsymbol{H_3}&: ln( \frac{\text{Aid to (domestic or foreign) NGOs}_{\text{USAID}}}{\text{Aid to other channels}_{\text{USAID}}} )_{i, t+1} &= \text{NGO legislation}_{it} + \text{controls}_{it}
\end{aligned}
$$ {#eq:all-models-dvs}

## General model specifications and controls

We use a standard set of controls in each model ([explained in more detail here](01_get-merge-data.html#other_controls_and_alternative_hypotheses)):

- Democracy: `polity`
- Wealth: `gdp.capita_log` (logged so it's on the same scale as the other variables) 
- Government capacity: `corruption`
- Bad stuff: `internal.conflict.past.5` and `natural_disaster.occurrence`

Following [Bell and Jones (2015)](http://dx.doi.org/10.1017/psrm.2014.7), we use crossed random effects for country and year and use a combination of meaned and demeaned versions of each continuous variable to estimate both the within and between effects of each variable. 

$$ y_{i, t + 1} = \beta_0 + \beta_1 (x_{it} - \bar{x}_i) + \beta_2 \bar{x}_i + \ldots $$

This approach has multiple benefits. The coefficients for the demeaned variables are roughly equivalent to their corresponding coefficients in a fixed effects model, but a fixed effects model assumes that the between effect (captured by the mean variables) is 0, which is not the case. A random effects model specified in this manner is more interpretable, as it clearly separates the within and between effects (again, within = demeaned, between = mean).

Here's proof of how it works in some simple models. Model 1 is a basic OLS with country fixed effects. Model 2 is a basic OLS with country random effects, but potentially misspecified, since the between and within effects are conflated. Model 3 is a basic OLS with country random effects specified with between (mean; $\bar{x}_i$) and within (demeaned; $x_{it} - \bar{x}_i$) coefficients. The demeaned/within coefficients in Model 3 are identical to the fixed effects coefficients in Model 1. If rows had been dropped because of listwise deletion (like, if there were missing values in one of independent variables), the coefficients would be slightly off, since the demeaned values would have been based on group means that included the values that were dropped (e.g. all 2013 rows are dropped because of lags, but the group means included 2013). This isn't  a problem in these reduced models, but that's one reason we impute all the data—we need the data to be as complete as possible to get the most accurate random effects.

```{r fixed-random-example, warning=FALSE, message=FALSE}
mod.test.fe <- lm(total.oda_log_next_year ~ barriers.total + polity + 
                    as.factor(cowcode),
                  data = df.country.aid.demean.next_year)

mod.test.re <- lmer(total.oda_log_next_year ~ barriers.total + polity + 
                      (1 | cowcode),
                    data = df.country.aid.demean.next_year)

mod.test.re.fancy <- lmer(total.oda_log_next_year ~ 
                            barriers.total_between + barriers.total_within +
                            polity_between + polity_within + 
                            (1 | cowcode),
                          data = df.country.aid.demean.next_year)

# Make named list of coefficients to include in the table
all_coefs <- data_frame(model = list(mod.test.fe, mod.test.re, mod.test.re.fancy)) %>% 
  mutate(tidy = model %>% map(tidy)) %>% 
  unnest(tidy) %>% 
  filter(!str_detect(term, "cowcode"), (effect != "ran_pars" | is.na(effect))) %>% 
  filter(!duplicated(term, fromLast = TRUE)) %>% 
  filter(term != "(Intercept)") %>% 
  left_join(coef.names.all, by = "term")
  
coefs_named <- all_coefs %>% pull(term) %>% 
  set_names(all_coefs$term_clean)

tbl_example <- huxreg(mod.test.fe, mod.test.re, mod.test.re.fancy, 
                      coefs = c(coefs_named, Constant = "(Intercept)"),
                      stars = NULL, statistics = c(N = "nobs"), note = "") %>% 
  insert_row(c("Country effects", "Fixed", "Random", "Random"),
             after = nrow(.) - 2, copy_cell_props = FALSE) 

tbl_example %>% print_hux()

tbl_example %>% 
  to_md(max_width = 100) %>% 
  cat(file = here("Output", "tbl-within-between-example.md"))
```

\
All of the models we run use imputed data ($m = 5$) with crossed year and country random effects. Most explanatory and control variables are included in their meaned and demeaned forms, except for any indicator variables (since you can't really average binary data). Additionally, we include the regular form of the current year's ODA to account for temporal autocorrelation in aid. We do not split current ODA into within and between versions so that mathematically it can be subtracted out of the next year's ODA in the dependent variable. Other mixed models functions like `nlme::lme()` allow you to define autoregressive correlation structures, but `lme4::lmer()` doesn't, so we account for time with this differenced approach instead. It's not perfect, but it works:

```{r show.acf.lags}
mod.test.no.oda <- lmer(total.oda_log_next_year ~ 
                          barriers.total_between + barriers.total_within +
                          polity_between + polity_within + 
                          gdp.capita_log_between + gdp.capita_log_within +
                          (1 | cowcode) + (1 | year),
                        data = filter(df.country.aid.demean.next_year.impute,
                                      m == "imp1"))

mod.test.oda.split <- lmer(total.oda_log_next_year ~ 
                             barriers.total_between + barriers.total_within +
                             polity_between + polity_within + 
                             total.oda_log_between + total.oda_log_within +
                             gdp.capita_log_between + gdp.capita_log_within +
                             (1 | cowcode) + (1 | year),
                           data = filter(df.country.aid.demean.next_year.impute,
                                         m == "imp1"))

mod.test.oda.nosplit <- lmer(total.oda_log_next_year ~ 
                               barriers.total_between + barriers.total_within +
                               polity_between + polity_within + 
                               total.oda_log +
                               gdp.capita_log_between + gdp.capita_log_within +
                               (1 | cowcode) + (1 | year),
                             data = filter(df.country.aid.demean.next_year.impute,
                                           m == "imp1"))

resid.no.oda <- acf(residuals(mod.test.no.oda), plot = FALSE)
resid.oda <- acf(residuals(mod.test.oda.nosplit), plot = FALSE)

ci.line <- qnorm((1 + 0.95) / 2) / sqrt(resid.no.oda$n.used)

acf.plot.data <- bind_rows(
  data_frame(Lag = resid.no.oda$lag[,,1], ACF = resid.no.oda$acf[,,1], 
             model = "No ODA"),
  data_frame(Lag = resid.oda$lag[,,1], ACF = resid.oda$acf[,,1], 
             model = "Current year’s ODA")
)

ggplot(acf.plot.data, aes(x = Lag, y = ACF, fill = model)) +
  geom_bar(stat = "identity", position = position_dodge(width = 1), width = 0.5) +
  geom_hline(yintercept = 0, size = 1) +
  geom_hline(yintercept = c(ci.line, -ci.line), size = 0.5, linetype = "dashed") +
  guides(fill = guide_legend(title = NULL)) +
  theme_donors()
```

Not splitting current ODA into within and between also fixes another sticky mathematical issue. When the models are run with within and current ODA, the $\sigma$ value for within-country variability becomes 0 for whatever reason (maybe it swallows up too much country level variability?). When $\sigma = 0$, the between-group variability is too small to fully account for between effects, resulting in a "degenerate model" (see [pages 10–11 here](http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf)) and influencing the coefficients in weird ways. See below, where Model 1 uses the split current ODA and Model 2 doesn't: $\sigma$ in Model 2 exists and the coefficients are better estimated.

```{r h1-table-results, results="asis"}
huxreg(mod.test.oda.split, mod.test.oda.nosplit,
       tidy_args = list(effects = "fixed"),
       statistics = c(N = "nobs"))

bind_rows(
  as.data.frame(VarCorr(mod.test.oda.split)) %>% mutate(model = "(1)"),
  as.data.frame(VarCorr(mod.test.oda.nosplit)) %>% mutate(model = "(2)")
) %>% 
  mutate(grp = ordered(fct_inorder(grp))) %>%
  select(`Random variable` = grp, sdcor, model) %>%
  spread(model, sdcor) %>% pandoc.table()
```

---

## Results

The results of all models can be found in the ["Bayesian models" notebook](models-bayesian.html), since it takes so many hours to run them all.

---

## Summary of hypotheses

```{r hypotheses-summary, results="asis", message=FALSE, warning=FALSE}
findings.summary <- read_csv(here("Data", "data_manual", "findings_summary.csv"))

caption <- "Summary of findings {#tbl:findings-summary}"
findings.summary.table <- pandoc.table.return(findings.summary, justify = "lll",
                                              keep.line.breaks = TRUE, style = "grid",
                                              caption = caption)

cat(findings.summary.table)
cat(findings.summary.table, file = here("Output", "tbl-findings-summary.md"))
```

---

## Robustness checks

### Imputation

[As discussed over in the data cleaning file](../Data/get_merge_data.html#missingness_and_imputation), we impute data for the few variables that are missing. To show what difference imputation makes, the table below shows three pairs of models from H~1~. The first two models are run on non-imputed data (so missing observations are deleted listwise), the second two models are run on 5 sets of imputed data, and the last two models are run on 10 sets of imputed data. 

It's clear that imputation makes a substantial difference—note the big differences between coefficients. However, the number of imputed datasets doesn't seem to matter, since there are only trivial differences in coefficients when there are 5 and 10 datasets.

```{r robust-compare-imputations, message=FALSE, warning=FALSE, cache=TRUE}
mods.robust.check.m.next_year.raw <- df.country.aid.demean.next_year.all %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% 
           future_map(mod.h1.barriers.total,
                      "total.oda_log_next_year"),
         mod.h1.type.total = data %>% 
           future_map(mod.h1.type.total,
                      "total.oda_log_next_year"))

# Get model details and parameters
mods.robust.check.m.next_year <- mods.robust.check.m.next_year.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int = TRUE))

# Meld the imputed models
mods.robust.check.m.next_year.melded.original <- mods.robust.check.m.next_year %>%
  filter(m == "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.m5 <- mods.robust.check.m.next_year %>%
  filter(m %in% paste0("imp", 1:5)) %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.m10 <- mods.robust.check.m.next_year %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.all <- bind_rows(
  mods.robust.check.m.next_year.melded.original,
  mods.robust.check.m.next_year.melded.m5,
  mods.robust.check.m.next_year.melded.m10
) %>%
  mutate(imputations = data %>% map_dbl(~ nrow(.)),
         model.name = paste(model.name, imputations, sep = "_"))
```

```{r tbl-show-imputations, results="asis"}
stargazer.fake(mods.robust.check.m.next_year.melded.all) %>% cat()
```

### Neutral regulations {.tabset .tabset-fade .tabset-pills}

```{r robust-neutral-regulations, cache=TRUE}
mods.robust.neutral.regs.raw <- df.country.aid.demean.next_year.all %>%
  nest(-m) %>%
  mutate(mod.h1.neutral.reg = data %>% 
           future_map(mod.h1.neutral.reg,
                      "total.oda_log_next_year"),
         mod.h1.neutral.fund = data %>% 
           future_map(mod.h1.neutral.fund,
                      "total.oda_log_next_year"),
         mod.h2.neutral.reg = data %>% 
           future_map(mod.h2.neutral.reg,
                      "prop.contentious_logit_next_year"),
         mod.h2.neutral.fund = data %>% 
           future_map(mod.h2.neutral.fund,
                      "prop.contentious_logit_next_year"))

mods.robust.neutral.regs.raw.h3 <- df.country.aid.us.demean.next_year.both %>%
  nest(-m) %>%
  mutate(mod.h3.dom.neutral.reg = data %>% 
           future_map(mod.h3.dom.neutral.reg,
                      "prop.ngo.dom_logit_next_year"),
         mod.h3.dom.neutral.fund = data %>% 
           future_map(mod.h3.dom.neutral.fund,
                      "prop.ngo.dom_logit_next_year"),
         mod.h3.for.neutral.reg = data %>% 
           future_map(mod.h3.for.neutral.reg,
                      "prop.ngo.foreign_logit_next_year"),
         mod.h3.for.neutral.fund = data %>% 
           future_map(mod.h3.for.neutral.fund,
                      "prop.ngo.foreign_logit_next_year"))

# Get model details and parameters
mods.robust.neutral.regs <- mods.robust.neutral.regs.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int = TRUE))

mods.robust.neutral.regs.h3 <- mods.robust.neutral.regs.raw.h3 %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int = TRUE))

# Meld the imputed models
mods.robust.neutral.regs.melded.h1 <- mods.robust.neutral.regs %>%
  filter(m != "original", str_detect(model.name, "h1")) %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.neutral.regs.melded.h2 <- mods.robust.neutral.regs %>%
  filter(m != "original", str_detect(model.name, "h2")) %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(~ meld.imputed.models(., exponentiate = TRUE)))

mods.robust.neutral.regs.melded.h3 <- mods.robust.neutral.regs.h3 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(~ meld.imputed.models(., exponentiate = TRUE)))
```

#### Neutral regulations and overall aid (H1)

```{r tbl-show-neutral-h1, results="asis"}
table.robust.neutral.regs.h1 <- mods.robust.neutral.regs.melded.h1 %>%
  stargazer.fake(exponentiate = FALSE) %>%
  cat()
```

#### Neutral regulations and tamer causes (H2)

```{r tbl-show-neutral-h2, results="asis"}
table.robust.neutral.regs.h2 <- mods.robust.neutral.regs.melded.h2 %>%
  filter(str_detect(model.name, "h2")) %>%
  stargazer.fake(exponentiate = TRUE) %>%
  cat()
```

#### Neutral regulations and NGOs (H3)

```{r tbl-show-neutral-h3, results="asis"}
table.robust.neutral.regs.h3 <- mods.robust.neutral.regs.melded.h3 %>%
  stargazer.fake(exponentiate = TRUE) %>%
  cat()
```


### Longer lags: H~1~ {.tabset .tabset-fade .tabset-pills}

Looking at aid 2 years and 5 years after the change in anti-NGO legislation shows similar trends to 1 year after.

```{r h1-models-2, warning=FALSE, message=FALSE, cache=TRUE}
mods.h1.after_2.raw <- df.country.aid.demean.after_2.impute %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% 
           future_map(mod.h1.barriers.total, "total.oda_log_next_year"),
         mod.h1.type.total = data %>% 
           future_map(mod.h1.type.total, "total.oda_log_next_year"),
         mod.h1.csre = data %>% 
           future_map(mod.h1.csre, "total.oda_log_next_year"))

# Get model details and parameters
mods.h1.after_2 <- mods.h1.after_2.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int = TRUE))

# Meld the imputed models
mods.h1.after_2.melded <- mods.h1.after_2 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

```{r h1-models-5, warning=FALSE, message=FALSE, cache=TRUE}
mods.h1.after_5.raw <- df.country.aid.demean.after_5.impute %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% 
           future_map(mod.h1.barriers.total, "total.oda_log_next_year"),
         mod.h1.type.total = data %>% 
           future_map(mod.h1.type.total, "total.oda_log_next_year"),
         mod.h1.csre = data %>% 
           future_map(mod.h1.csre, "total.oda_log_next_year"))

# Get model details and parameters
mods.h1.after_5 <- mods.h1.after_5.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int = TRUE))

# Meld the imputed models
mods.h1.after_5.melded <- mods.h1.after_5 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

#### Effect on ODA after 2 years

```{r h1-melded-table-2, results="asis", warning=FALSE}
stargazer.fake(mods.h1.after_2.melded) %>% cat()
```

#### Effect on ODA after 5 years

```{r h1-melded-table-5, results="asis", warning=FALSE}
stargazer.fake(mods.h1.after_5.melded) %>% cat()
```


### Longer lags: H~2~ {.tabset .tabset-fade .tabset-pills}

```{r h2-models-2, warning=FALSE, message=FALSE, cache=TRUE}
mods.h2.after_2.raw <- df.country.aid.demean.after_2.impute %>%
  nest(-m) %>%
  mutate(mod.h2.barriers.total = data %>% 
           future_map(mod.h2.barriers.total, "prop.contentious_logit_next_year"),
         mod.h2.type.total = data %>% 
           future_map(mod.h2.type.total, "prop.contentious_logit_next_year"),
         mod.h2.csre = data %>% 
           future_map(mod.h2.csre, "prop.contentious_logit_next_year"))

# Get model details and parameters
mods.h2.after_2 <- mods.h2.after_2.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int = TRUE))

# Meld the imputed models
mods.h2.after_2.melded <- mods.h2.after_2 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

```{r h2-models-5, warning=FALSE, message=FALSE, cache=TRUE}
mods.h2.after_5.raw <- df.country.aid.demean.after_5.impute %>%
  nest(-m) %>%
  mutate(mod.h2.barriers.total = data %>% 
           future_map(mod.h2.barriers.total, "prop.contentious_logit_next_year"),
         mod.h2.type.total = data %>% 
           future_map(mod.h2.type.total, "prop.contentious_logit_next_year"),
         mod.h2.csre = data %>% 
           future_map(mod.h2.csre, "prop.contentious_logit_next_year"))

# Get model details and parameters
mods.h2.after_5 <- mods.h2.after_5.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int = TRUE))

# Meld the imputed models
mods.h2.after_5.melded <- mods.h2.after_5 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

#### Effect on contentious aid after 2 years

```{r h2-melded-table-2, results="asis", warning=FALSE}
stargazer.fake(mods.h2.after_2.melded) %>% cat()
```

#### Effect on contentious aid after 5 years

```{r h2-melded-table-5, results="asis", warning=FALSE}
stargazer.fake(mods.h2.after_5.melded) %>% cat()
```
