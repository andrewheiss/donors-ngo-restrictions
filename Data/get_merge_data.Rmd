---
title: "Get, clean, and merge data"
author: "Suparna Chaudhry and Andrew Heiss"
date: "`r format(Sys.time(), '%B %e, %Y')`"
output: 
  html_document: 
    css: ../html/fixes.css
    code_folding: hide
    toc: yes
    toc_float: true
    toc_depth: 4
    highlight: pygments
    self_contained: yes
    theme: spacelab
    includes:
      after_body: ../html/add_home_link.html
---

```{r load-libraries, message=FALSE}
knitr::opts_chunk$set(cache=FALSE, fig.retina=2,
                      tidy.opts=list(width.cutoff=120),  # For code
                      options(width=120))  # For output

library(tidyverse)
library(stringr)
library(lubridate)
library(httr)
library(rvest)
library(countrycode)
library(readxl)
library(pander)
library(DT)
library(WDI)
library(xml2)
library(ggstance)

source(file.path(PROJHOME, "lib", "graphics.R"))

panderOptions('table.split.table', Inf)
panderOptions('table.split.cells', Inf)
panderOptions('keep.line.breaks', TRUE)
panderOptions('table.style', 'multiline')
panderOptions('table.alignment.default', 'left')
```

## Consistent country names

This is a perpetual nightmare in IR data. Here's a master lookup table of COW codes, ISO3 codes, ISO2 codes, and Gleditsch Ward codes. 

Gleditsch and Ward do not include a bunch of countries, so I create my own codes for relevant countries that appear in other datasets:

- Somaliland: 521
- Palestine (West Bank): 667
- Palestine (Gaza): 668
- Palestine (both): 669
- Hong Kong: 715

Also, [following Gleditsch and Ward](http://privatewww.essex.ac.uk/~ksg/data/iisyst_casedesc.pdf), I treat Serbia as 340 and Serbia & Montenegro as a continuation of Yugoslavia, or 345.

```{r load-gwcodes, message=FALSE}
# Gleditsch Ward codes
gw.date <- "%d:%m:%Y"
gw.states <- read_tsv("http://privatewww.essex.ac.uk/~ksg/data/iisystem.dat",
                      col_names=c("gwcode", "cowc", "country.name",
                                  "date.start", "date.end"),
                      col_types=cols(
                        gwcode = col_integer(),
                        cowc = col_character(),
                        country.name = col_character(),
                        date.start = col_date(format=gw.date),
                        date.end = col_date(format=gw.date)
                      ),
                      locale=locale(encoding="windows-1252"))

gw.microstates <- read_tsv("http://privatewww.essex.ac.uk/~ksg/data/microstatessystem.dat",
                           col_names=c("gwcode", "cowc", "country.name",
                                       "date.start", "date.end"),
                           col_types=cols(
                             gwcode = col_integer(),
                             cowc = col_character(),
                             country.name = col_character(),
                             date.start = col_date(format=gw.date),
                             date.end = col_date(format=gw.date)
                           ),
                           locale=locale(encoding="windows-1252"))

gw.codes <- bind_rows(gw.states, gw.microstates) %>%
  filter(date.end > ymd("2000-01-01")) %>%
  # Help out countrycode() 
  mutate(country.name = recode(country.name,
                               `Vietnam, Democratic Republic of` = "Vietnam",
                               `Yemen (Arab Republic of Yemen)` = "Yemen")) %>%
  mutate(iso3 = countrycode(country.name, "country.name", "iso3c"),
         iso2 = countrycode(iso3, "iso3c", "iso2c"),
         cowcode = countrycode(iso3, "iso3c", "cown")) %>%
  mutate(iso3 = case_when(
    .$gwcode == 340 ~ "SRB",
    .$gwcode == 347 ~ "XKK",
    TRUE ~ .$iso3
  )) %>%
  mutate(iso2 = case_when(
    .$gwcode == 347 ~ "XK",
    TRUE ~ .$iso2
  )) %>%
  mutate(cowcode = case_when(
    .$gwcode == 340 ~ as.integer(340),
    .$gwcode == 347 ~ as.integer(347),
    TRUE ~ .$cowcode
  )) %>%
  filter(!is.na(iso3)) %>%
  mutate(country.name = countrycode(iso3, "iso3c", "country.name"),
         country.name = ifelse(iso3 == "XKK", "Kosovo", country.name)) %>%
  select(country.name, iso3, iso2, gwcode, cowcode)

manual.gw <- tribble(
  ~country.name,            ~iso3,  ~iso2,   ~gwcode,  ~cowcode,
  "Somaliland",             "SOL",  NA,      521,      521,     
  "Palestine (West Bank)",  "PWB",  NA,      667,      667,     
  "Palestine (Gaza)",       "PGZ",  NA,      668,      668,     
  "Palestine",              "PSE",  "PS",    669,      669,     
  "Hong Kong",              "HKG",  "HK",    715,      715
)

gw.codes <- bind_rows(gw.codes, manual.gw) %>% 
  arrange(country.name)

gw.codes %>% datatable()
```


## Foreign aid

### OECD and AidData

The OECD collects detailed data on all foreign aid flows (ODA) from OECD member countries (and some non-member countries), mulilateral organizations, and the Bill and Melinda Gates Foundation (for some reason they're the only nonprofit donor) to all DAC-eligible countries (and some non non-DAC-eligible countries). 

The OECD tracks all this in a centralized Creditor Reporting System database and provides a nice front end for it at [OECD.Stat](http://stats.oecd.org/) with an open (but inscrutable) API ([raw CRS data](http://stats.oecd.org/DownloadFiles.aspx?HideTopMenu=yes&DatasetCode=CRS1) is also available). There are a set of pre-built queries with information about ODA flows by donor, recipient, and sector (purpose), but the pre-built data sources do not include all dimensions of the data. For example, [Table DAC2a](http://stats.oecd.org/Index.aspx?DataSetCode=TABLE2A) includes columns for donor, recipient, year, and total ODA (e.g. the US gave \$X to Nigeria in 2008) , but does not indicate the purpose/sector for the ODA. [Table DAC5](http://stats.oecd.org/Index.aspx?DataSetCode=TABLE5) includes columns for the donor, sector, year, and total ODA (e.g. the US gave \$X for education in 2008), but does not include recipient information. 

Instead of using these pre-built queries or attempting to manipulate their parameters, it's possible to use the [OECD's QWIDS query builder](https://stats.oecd.org/qwids/) to create a custom download of data. However, it is slow and clunky and requires singificant munging and filtering after exporting. 

The solution to all of this is to use [data from AidData](http://aiddata.org/aiddata-research-releases), which imports raw data from the OECD, cleans it, verifies it, and makes it freely available on GitHub.

AidData offers multiple versions of the data, including a full release, a thin release, aggregated donor/recipient/year data, and aggregated donor/recipient/year/purpose data. For the purposes of this study, all we care about are ODA flows by donor, recipient, year, and purpose, which is one of the ready-made datasets. 

Notably, this aggregated data shows total aid *commitments*, not aid *disbursements*. Both types of ODA information are available from the OECD and it's possible to get them using OECD's raw data. However, [AidData notes](http://aiddata.org/faqs-about-our-data) that disbursment data is sticky and slow—projects take a long time to fulfil and actual inflows of aid in a year can be tied to commitments made years before. Because we're interested in donor reactions to restrictions on NGOs, any reaction would be visible in the decision to commit money to aid, not in the ultimate disbursement of aid, which is most likely already legally obligated and allocated to the country regardless of restrictions.

So, we look at ODA *commitments*.

```{r load-aiddata, message=FALSE, warning=FALSE}
aiddata.url <- "https://github.com/AidData-WM/public_datasets/releases/download/v3.0/AidDataCore_ResearchRelease_Level1_v3.0.zip"
aiddata.path <- file.path(PROJHOME, "Data", "data_raw", "AidData")
aiddata.zip.name <- basename(aiddata.url)
aiddata.name <- tools::file_path_sans_ext(aiddata.zip.name)

aiddata.final.name <- "AidDataCoreDonorRecipientYearPurpose_ResearchRelease_Level1_v3.0.csv"

# Download AidData data if needed
if (!file.exists(file.path(aiddata.path, aiddata.final.name))) {
  aiddata.get <- GET(aiddata.url, 
                     write_disk(file.path(aiddata.path, aiddata.zip.name),
                                overwrite=TRUE), 
                     progress())
  unzip(file.path(aiddata.path, aiddata.zip.name), exdir=aiddata.path)
  
  # Clean up zip file and unnecessary CSV files
  file.remove(file.path(aiddata.path, aiddata.zip.name))
  list.files(aiddata.path, pattern="csv", full.names=TRUE) %>%
    map(~ ifelse(str_detect(.x, "DonorRecipientYearPurpose"), 0,
                 file.remove(file.path(.x))))
}

# Clean up AidData data
aiddata.raw <- read_csv(file.path(aiddata.path, aiddata.final.name),
                        col_types=cols(
                          donor = col_character(),
                          recipient = col_character(),
                          year = col_integer(),
                          coalesced_purpose_code = col_double(),
                          coalesced_purpose_name = col_character(),
                          commitment_amount_usd_constant_sum = col_double()
                        ))

aiddata.clean <- aiddata.raw %>%
  # Get rid of non-country recipients
  filter(!str_detect(recipient,
                     regex("regional|unspecified|multi|value|global|commission", 
                           ignore_case=TRUE))) %>%
  filter(year < 9999) %>%
  mutate(purpose.code.short = as.integer(str_sub(coalesced_purpose_code, 1, 3)))

# Donor, recipient, and purpose details
# I pulled these country names out of the dropdown menu at OECD.Stat Table 2a online
dac.donors <- c("Australia", "Austria", "Belgium", "Canada", "Czech Republic",
                "Denmark", "Finland", "France", "Germany", "Greece", "Iceland",
                "Ireland", "Italy", "Japan", "Korea", "Luxembourg", "Netherlands",
                "New Zealand", "Norway", "Poland", "Portugal", "Slovak Republic",
                "Slovenia", "Spain", "Sweden", "Switzerland", "United Kingdom",
                "United States")

non.dac.donors <- c("Bulgaria", "Croatia", "Cyprus", "Estonia", "Hungary",
                    "Israel", "Kazakhstan", "Kuwait", "Latvia", "Liechtenstein",
                    "Lithuania", "Malta", "Romania", "Russia", "Saudi Arabia",
                    "Chinese Taipei", "Thailand", "Timor Leste", "Turkey",
                    "United Arab Emirates")

other.countries <- c("Brazil", "Chile", "Colombia", "India", "Monaco", "Qatar",
                     "South Africa", "Taiwan")

donors <- aiddata.clean %>%
  distinct(donor) %>%
  mutate(donor.type = case_when(
    .$donor %in% c(dac.donors, non.dac.donors, other.countries) ~ "Country",
    .$donor == "Bill & Melinda Gates Foundation" ~ "Private donor",
    TRUE ~ "Multilateral or IGO"
  )) %>%
  mutate(donor.cowcode = ifelse(donor.type == "Country",
                                countrycode(donor, "country.name", "cown"),
                                NA),
         donor.iso3 = ifelse(donor.type == "Country",
                             countrycode(donor, "country.name", "iso3c"),
                             NA))

recipients <- aiddata.clean %>%
  distinct(recipient) %>%
  mutate(iso3 = countrycode(recipient, "country.name", "iso3c")) %>%
  mutate(iso3 = case_when(
    .$recipient == "Kosovo" ~ "XKK",
    .$recipient == "Serbia and Montenegro" ~ "YUG",
    TRUE ~ .$iso3
  )) %>%
  left_join(gw.codes, by="iso3") %>%
  # Get rid of tiny countries
  filter(!is.na(gwcode))

# Purposes
purposes <- aiddata.clean %>%
  count(coalesced_purpose_name, coalesced_purpose_code)

purposes.url <- "https://www.oecd.org/dac/stats/documentupload/DAC_codeLists.xml"
purpose.nodes <- read_xml(purposes.url) %>% xml_find_all("//codelist-item")

purpose.codes <- data_frame(
  code = purpose.nodes %>% xml_find_first(".//code") %>% xml_text(),
  category = purpose.nodes %>% xml_find_first(".//category") %>% xml_text(),
  name = purpose.nodes %>% xml_find_first(".//name") %>% xml_text(),
  description = purpose.nodes %>% xml_find_first(".//description") %>% xml_text()
) %>%
  mutate(code = as.integer(code))

# Extract the general categories of aid purposes (i.e. the first three digits of the purpose codes)
general.codes <- purpose.codes %>%
  filter(code %in% as.character(100:1000) & str_detect(name, "^\\d")) %>%
  mutate(code = as.integer(code)) %>%
  select(purpose.code.short = code, purpose.category.name = name) %>%
  mutate(purpose.category.clean = str_replace(purpose.category.name,
                                              "\\d\\.\\d ", "")) %>%
  separate(purpose.category.clean,
           into=c("purpose.sector", "purpose.category"), 
           sep=", ") %>%
  mutate_at(vars(c(purpose.sector, purpose.category)), funs(str_to_title(.))) %>%
  select(-purpose.category.name)

# These 7 codes are weird and get filtered out inadvertantly
codes.not.in.oecd.list <- tribble(
  ~purpose.code.short, ~purpose.sector, ~purpose.category,
  100,                 "Social",        "Social Infrastructure",
  200,                 "Eco",           "Economic Infrastructure",
  300,                 "Prod",          "Production",
  310,                 "Prod",          "Agriculture",
  320,                 "Prod",          "Industry",
  420,                 "Multisector",   "Women in development",
  # NB: This actually is splict between 92010 (domestic NGOs), 92020
  # (international NGOs), and 92030 (local and regional NGOs)
  920,                 "Non Sector",    "Support to NGOs"
)

purpose.codes.clean <- general.codes %>%
  bind_rows(codes.not.in.oecd.list) %>%
  arrange(purpose.code.short) %>%
  mutate(purpose.contentiousness = "")

# Manually code contentiousness of purposes
write_csv(purpose.codes.clean,
          file.path(PROJHOME, "Data", "data_clean",
                    "purpose_codes_contention_WILL_BE_OVERWRITTEN.csv"))

purpose.codes.contentiousness <- read_csv(file.path(PROJHOME, "Data", "data_clean",
                                                    "purpose_codes_contention.csv"))

aiddata.final <- aiddata.clean %>%
  left_join(donors, by="donor") %>%
  left_join(recipients, by="recipient") %>%
  left_join(purpose.codes.contentiousness, by="purpose.code.short") %>%
  select(donor, donor.type, donor.cowcode, donor.iso3, year,
         country.name, cowcode, gwcode, iso2, iso3,
         oda = commitment_amount_usd_constant_sum,
         purpose.code.short, purpose.sector, purpose.category,
         purpose.contentiousness,
         coalesced_purpose_code, coalesced_purpose_name) %>%
  arrange(cowcode, year)
```

#### List of donors

```{r}
donors %>% datatable()
```

#### List of recipients

```{r}
select(recipients, recipient) %>% datatable()
```

#### List of purposes

```{r}
arrange(purposes, desc(n)) %>% datatable()
```

#### Summary of clean data

```{r aiddata-summary}
aiddata.final %>% glimpse()
```

### USAID

USAID provides the complete dataset for its [Foreign Aid Explorer](https://explorer.usaid.gov/aid-dashboard.html) as a [giant CSV file](https://explorer.usaid.gov/data.html). The data includes both economic and military aid, but it's easy to filter out the military aid. Here we only look at obligations, not disbursements, so that the data is comparable to the OECD data from AidData.

```{r load-usaid, message=FALSE, cache=TRUE}
usaid.url <- "https://explorer.usaid.gov/prepared/us_foreign_aid_complete.csv"
usaid.path <- file.path(PROJHOME, "Data", "data_raw", "USAID")
usaid.name <- basename(usaid.url)

# Download USAID data if needed
if (!file.exists(file.path(usaid.path, usaid.name))) {
  usaid.get <- GET(usaid.url, 
                   write_disk(file.path(usaid.path, usaid.name),
                              overwrite=TRUE), 
                   progress())
}

# Clean up USAID data
usaid.raw <- read_csv(file.path(usaid.path, usaid.name),
                      na = c("", "NA", "NULL"),
                      col_types=cols(
                        country_id = col_integer(),
                        country_code = col_character(),
                        country_name = col_character(),
                        region_id = col_integer(),
                        region_name = col_character(),
                        income_group_id = col_integer(),
                        income_group_name = col_character(),
                        income_group_acronym = col_character(),
                        implementing_agency_id = col_integer(),
                        implementing_agency_acronym = col_character(),
                        implementing_agency_name = col_character(),
                        implementing_subagency_id = col_integer(),
                        subagency_acronym = col_character(),
                        subagency_name = col_character(),
                        channel_category_id = col_integer(),
                        channel_category_name = col_character(),
                        channel_subcategory_id = col_integer(),
                        channel_subcategory_name = col_character(),
                        channel_id = col_integer(),
                        channel_name = col_character(),
                        dac_category_id = col_integer(),
                        dac_category_name = col_character(),
                        dac_sector_code = col_integer(),
                        dac_sector_name = col_character(),
                        dac_purpose_code = col_integer(),
                        dac_purpose_name = col_character(),
                        funding_account_id = col_character(),
                        funding_account_name = col_character(),
                        funding_agency_id = col_integer(),
                        funding_agency_name = col_character(),
                        funding_agency_acronym = col_character(),
                        assistance_category_id = col_integer(),
                        assistance_category_name = col_character(),
                        aid_type_group_id = col_integer(),
                        aid_type_group_name = col_character(),
                        activity_id = col_integer(),
                        activity_name = col_character(),
                        activity_project_number = col_character(),
                        activity_start_date = col_date(format = ""),
                        activity_end_date = col_date(format = ""),
                        transaction_type_id = col_integer(),
                        transaction_type_name = col_character(),
                        fiscal_year = col_character(),
                        current_amount = col_double(),
                        constant_amount = col_double(),
                        USG_sector_id = col_integer(),
                        USG_sector_name = col_character(),
                        submission_id = col_integer(),
                        numeric_year = col_double()
                      ))

usaid.clean <- usaid.raw %>%
  filter(assistance_category_name == "Economic") %>%
  filter(transaction_type_name == "Obligations")

# Get rid of this because it's huge and taking up lots of memory
rm(usaid.raw)
```

#### Implementing agencies

Here are the US government agencies giving out money:

```{r}
implementing.agencies <- usaid.clean %>%
  count(implementing_agency_name, subagency_name) %>%
  arrange(desc(n), implementing_agency_name)

implementing.agencies %>% datatable()
```


#### Activities

The activities listed don't follow any standard coding guidelines. There are tens of thousands of them. Here are the first 100, just for reference:

```{r}
activities <- usaid.clean %>%
  count(activity_name) %>%
  slice(1:100)

activities %>% datatable()
```

#### Channels

USAID distinguishes between domestic, foreign, and international NGOs, companies, multilateral organizations, etc. recipients (or channels) of money:

```{r}
channels <- usaid.clean %>%
  count(channel_category_name, channel_subcategory_name) %>%
  filter(!is.na(channel_category_name))

channels %>% datatable(options=list(pageLength=20))
```

#### Summary of clean data

```{r usaid-summary}
usaid.clean %>% glimpse()
```


## NGO regulations

### NGO legislation

In 2013, Darin Christensen and Jeremy Weinstein collected [detailed data](https://darinchristensen.github.io/research/#protest-and-repression) on NGO regulations for [their *Journal of Democracy* article](http://www.journalofdemocracy.org/article/defunding-dissent-restrictions-aid-ngos). Suparna Chaudhry expanded this data as part of her dissertation research, but wants her data embargoed until some of her work is publsihed. To prevent data leakage, the code to make minor manual adjustments is included in an untracked file and not made public.

The code below will still work on the original Christensen and Weinstein data, but it will (obviously) not include Chaudhry's expanded data.

```{r load-dcjw, warning=FALSE}
# Original DCJW data
dcjw.orig.path <- file.path(PROJHOME, "Data", "data_raw", "DCJW NGO Laws",
                            "DCJW_NGO_Laws.xlsx")

dcjw.orig <- read_excel(dcjw.orig.path)[,1:50] %>%
  select(-c(dplyr::contains("source"), dplyr::contains("burden"), 
            dplyr::contains("subset"), Coder, Date))


# Tidy DCJW data
dcjw.path <- file.path(PROJHOME, "Data", "data_raw", "DCJW NGO Laws",
                       "Admn Crackdown_updated.xlsx")

dcjw.questions.clean <- tribble(
  ~question,  ~question_clean,
  "q_1a",     "const_assoc",
  "q_1b",     "politcial_parties",
  "q_2a",     "ngo_register",
  "q_2b",     "ngo_register_burden",
  "q_2c",     "ngo_register_appeal",
  "q_2d",     "ngo_barrier_foreign_funds",
  "q_3a",     "ngo_disclose_funds",
  "q_3b",     "ngo_foreign_fund_approval",
  "q_3c",     "ngo_foreign_fund_channel",
  "q_3d",     "ngo_foreign_fund_restrict",
  "q_3e",     "ngo_foreign_fund_prohibit",
  "q_3f",     "ngo_type_foreign_fund_prohibit",
  "q_4a",     "ngo_politics",
  "q_4b",     "ngo_politics_intimitation",
  "q_4c",     "ngo_politics_foreign_fund"
)

dcjw.barriers.clean <- tribble(
  ~question_cat,  ~barrier,
  "1",            "association",
  "2",            "entry",
  "3",            "funding",
  "4",            "advocacy"
)

dcjw <- read_excel(dcjw.path)[,1:50] %>%
  select(-c(dplyr::contains("source"), dplyr::contains("burden"), 
            dplyr::contains("subset"), Coder, Date)) %>%
  gather(key, value, -Country) %>%
  separate(key, c("question", "var.name"), 4) %>%
  filter(!is.na(Country)) %>%
  mutate(var.name = ifelse(var.name == "", "value", gsub("_", "", var.name))) %>%
  spread(var.name, value) %>%
  # Get rid of rows where year is missing and regulation was not imposed
  filter(!(is.na(year) & value == 0)) %>%
  # Some entries have multiple years; for now just use the first year
  mutate(year = str_split(year, ",")) %>% unnest(year) %>% 
  group_by(Country, question) %>% slice(1) %>% ungroup() %>%
  mutate(value = as.integer(value), year = as.integer(year)) %>%
  # If year is missing but some regulation exists, assume it has always already
  # existed (since 1950, arbitrarily)
  mutate(year = ifelse(is.na(year), 1950, year))

potential.dcjw.panel.question <- dcjw %>%
  tidyr::expand(Country, question, 
                year = min(.$year, na.rm=TRUE):2015)

dcjw.panel.all.laws <- dcjw %>%
  right_join(potential.dcjw.panel.question,
             by=c("Country", "question", "year"))

# Suparna Chaudry updated the original DCJW data, but wants the data embargoed 
# until some of her dissertation is published. To prevent data leakage onto the
# internet, minor manual adjustments are included in a hidden file here instead
# of this main file.
source(file.path(PROJHOME, "Data", "data_raw", "DCJW NGO Laws",
                 "chaudhry_manual_changes.R"))

dcjw.panel.all.laws <- dcjw.panel.all.laws %>%
  group_by(Country, question) %>%
  # Bring most recent legislation forward
  mutate(value = zoo::na.locf(value, na.rm=FALSE)) %>%
  mutate(not.all.na = !all(is.na(value))) %>%
  ungroup() %>%
  # Set defaults for columns that aren't all NA
  # I could be fancy and consolidate these conditionals into just one, but this
  # gives us more flexibility to set different defaults per law (like how q_2b
  # or q_4c might be better as NA_integer_ instead of 0)
  mutate(value.fixed = case_when(
    .$not.all.na & is.na(value) & .$question == "q_1a" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_1b" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_2a" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_2b" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_2c" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_2d" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_3a" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_3b" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_3c" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_3d" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_3e" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_3f" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_4a" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_4b" ~ as.integer(0),
    .$not.all.na & is.na(value) & .$question == "q_4c" ~ as.integer(0),
    TRUE ~ .$value
  )) %>%
  select(-not.all.na, -value) %>%
  spread(question, value.fixed) %>%
  ungroup()

potential.dcjw.panel.barrier <- potential.dcjw.panel.question %>%
  mutate(question_cat = substr(question, 3, 3)) %>%
  left_join(dcjw.barriers.clean, by="question_cat") %>%
  distinct(Country, year, barrier)

dcjw.panel.barriers <- dcjw.panel.all.laws %>%
  gather(question, value, -Country, -year) %>%
  mutate(question_cat = substr(question, 3, 3)) %>%
  left_join(dcjw.barriers.clean, by="question_cat") %>%
  # Make an index for each type of barrier
  mutate(value = case_when(
    # Reverse values for associational rights
    .$question == "q_1a" & .$value == 0 ~ as.integer(1),
    .$question == "q_1a" & .$value == 1 ~ as.integer(0),
    .$question == "q_1b" & .$value == 0 ~ as.integer(1),
    .$question == "q_1b" & .$value == 1 ~ as.integer(0),
    # Reverse value for q_2c
    .$question == "q_2c" & .$value == 0 ~ as.integer(1),
    .$question == "q_2c" & .$value == 1 ~ as.integer(0),
    TRUE ~ .$value
  )) %>%
  group_by(Country, year, barrier) %>%
  # Add up all the barriers for each country year
  # Use a floor of zero to account for negative values
  summarise(index = sum(value, na.rm=TRUE)) %>%
  mutate(index = ifelse(index < 0, as.integer(0), index)) %>%
  # Join with full possible panel
  right_join(potential.dcjw.panel.barrier,
             by=c("Country", "barrier", "year")) %>%
  spread(barrier, index) %>%
  ungroup() %>%
  # Standardize barrier indexes by dividing by maximum number possible
  mutate(association.std = association / 2,
         entry.std = entry / 4,
         funding.std = funding / 8,
         advocacy.std = advocacy / 4) %>%
  mutate(barriers.total = advocacy + association + entry + funding,
         barriers.std.total = advocacy.std + association.std + entry.std + funding.std)

dcjw.full <- dcjw.panel.all.laws %>%
  left_join(dcjw.panel.barriers, by=c("Country", "year")) %>%
  # Lop off the ancient observations
  filter(year > 1980) %>%
  # Rename q_* variables
  rename_(.dots = setNames(dcjw.questions.clean$question, 
                           dcjw.questions.clean$question_clean)) %>%
  # Add additional variables
  mutate(Country = countrycode(Country, "country.name", "country.name"),
         cowcode = countrycode(Country, "country.name", "cown"),
         cowcode = ifelse(Country == "Serbia", 340, cowcode)) %>%
  select(country.name = Country, cowcode, year, everything())
```

Chaudhry's data augments Christensen and Weinstein's data substantially. Christensen and Weinstein include information for `r nrow(dcjw.orig)` countries, while Chaudhry includes `r length(unique(dcjw.full$country.name))` countries.

In addition to panel data on the presence or absence of specific NGO regulations, we create several indexes for each of the categories of regulation, [following Christensen and Weinstein's classification](https://darinchristensen.github.io/Data/DCJW_Codebook.pdf):

- `association` (Q1a, Q1b; 2 points maximum): barriers to associational rights
    - Q1a and Q1b are reversed, so *not* having the constitutional right to assembly earns 1 point. 
- `entry` (Q2a, Q2b, Q2c, Q2d; 4 points maximum): barriers to entry
    - Q2c is reversed, so *not* being allowed to appeal registration status earns 1 point.
- `funding` (Q3a, Q3b, Q3c, Q3d, Q3e, Q3f; 8 points maximum): barriers to funding
- `advocacy` (Q4a, Q4b, Q4c; 4 points maximum): barriers to advocacy
- `barriers.total` (18 points maximum, though actual max is `r max(dcjw.full$barriers.total)`): sum of all four indexes

These indexes are also standardized by dividing by the maximum, yielding the following variables:

- `association.std`: 1 point maximum, actual max = `r max(dcjw.full$association.std)`
- `entry.std`: 1 point maximum, actual max = `r max(dcjw.full$entry.std)`
- `funding.std`: 1 point maximum, actual max = `r max(dcjw.full$funding.std)`
- `advocacy.std`: 1 point maximum, actual max = `r max(dcjw.full$advocacy.std)`
- `barriers.std.total`: 4 points maximum, actual max = `r max(dcjw.full$barriers.std.total)`

```{r dcjw-glimpse}
dcjw.full %>% glimpse()
```

#### Missingness

There is some missing data, even with backfilling data since we only backfill columns where a country has *some* observation (i.e. if there is never a value for a question in a country, all values are NA rather than the default). But when creating the indexes, these missing values are ignored, so there are no missing index values.

```{r dcjw-missing, fig.width=7, fig.height=5}
# https://github.com/njtierney/visdat
visdat::vis_miss(dcjw.full) + 
  theme_donors() +
  theme(legend.position="top",
        axis.text.x=element_text(angle=45, vjust=1, hjust=1))
```


### Civil society regulatory environment

An alternative way of measuring civil society restrictions is to look at the overal civil society regulatory environment rather than specific laws, since de jure restrictions do not always map clearly into de facto restrictions (especially in dictatorships where the implementation of laws is more discretionary). 

Andrew Heiss develops a new civil society regulatory environment index (CSRE) in his dissertation, which combines two civil society indexes from the [Varieties of Democracy project (V-Dem)](https://www.v-dem.net/en/): (1) civil society repression and (2) civil society entry and exit regulations. The CSRE ranges from roughly −6 to 6 (though typically only from −4 to 4ish), and shows more variation over time since it ostensibly captures changes in the implementation of the regulatory environment rather than the presence or absence of legislation. 

While the main focus of this paper is donor response to new *legislation*, we also look at donor response to changes in the overall CSRE as a robustness check.

```{r load-vdem}
# There's no direct link for V-Dem data, since it's behind a contact
# information form. So, download the 6.2 version of the "Country-Year: V-Dem +
# other" dataset from https://www.v-dem.net/en/data/data-version-6-2/ and place
# it in PROJHOME/Data/data_raw/V-Dem/v6.2
#
# readr likes to incorrectly guess that most col_double columns are
# col_integer, mostly because of the low default max_guess threshold. You can
# either bump up that threshold, or prespecify column types, using col_double
# as the default type.
vdem.raw <- read_csv(file.path(PROJHOME, "Data", "data_raw", 
                                    "V-Dem", "v6.2",
                                    "V-Dem-DS-CY-v6.2.csv"),
                  col_types=cols(
                              country_name = col_character(),
                              country_id = col_integer(),
                              country_text_id = col_character(),
                              year = col_integer(),
                              historical_date = col_date(format=""),
                              codingstart = col_integer(),
                              gapstart = col_integer(),
                              gapend = col_integer(),
                              codingend = col_integer(),
                              COWcode = col_integer(),
                              v2elregnam = col_character(),
                              v2ellocnam = col_character(),
                              v2exnamhos = col_character(),
                              v2extithos = col_character(),
                              v2lgnamelo = col_character(),
                              v2lgnameup = col_character(),
                              v2exnamhog = col_character(),
                              v2extithog = col_character(),
                              .default = col_double()
                            )) %>%
  # Missing COW codes
  mutate(COWcode = case_when(
    .$country_text_id == "SML" ~ as.integer(521),
    .$country_text_id == "PSE" ~ as.integer(667),
    .$country_text_id == "PSG" ~ as.integer(668),
    TRUE ~ .$COWcode))

# Extract civil society-related variables and create CSRE index
vdem.cso <- vdem.raw %>% select(country_name, year, cowcode = COWcode, 
                                v2x_frassoc_thick, v2xcs_ccsi,
                                starts_with("v2cseeorgs"), 
                                starts_with("v2csreprss"), 
                                starts_with("v2cscnsult"),
                                starts_with("v2csprtcpt"), 
                                starts_with("v2csgender"), 
                                starts_with("v2csantimv")) %>%
  mutate(v2csreprss_ord = factor(v2csreprss_ord, 
                                 labels=c("Severely", "Substantially", 
                                          "Moderately", "Weakly", "No"),
                                 ordered=TRUE),
         csre = v2csreprss + v2cseeorgs) %>%
  filter(year > 1980)
```

#### Civil society restrictions data

```{r}
vdem.cso.min <- vdem.cso %>%
  select(country_name, year, cowcode, csre, v2csreprss_ord,
         starts_with("v2csreprss"), starts_with("v2cseeorgs")) %>%
  arrange(cowcode, year)

vdem.cso.min %>% head(100) %>% datatable(extensions="Responsive")
```

#### Summary of clean data

```{r vdem-cso-summary}
vdem.cso.min %>% glimpse()
```


## Neighboring states

Calculate three types of distance between all countries with the [`CShapes` R package](https://cran.r-project.org/package=cshapes): mimimum distance, capital distance, and centroid distance. Because this takes a really long time, it's best to run `PROJHOME/Data/get_distances.R` separately elsewhere first (like on a VPS) and then save the resulting `.rds` files in `PROJHOME/Data/data_raw/Country Distances`. 

The `all.distances` data frame below contains all three distance types between every country and every other country in 2012 (though it could potentially include distances from 1991–2015). This is used later to weight variables by distance. It also includes an indicator variable called `is.rough.neighbor` that is true if the two countries are less than 900 km apart, which captures neighbor relationships better than simple contiguous borders.

```{r load-cshapes, message=FALSE, cache=TRUE}
distance.folder <- file.path(PROJHOME, "Data", "data_raw", "Country distances")

read_distances <- function(type, year) {
  stopifnot(year >= 1990, year <= 2015)
  stopifnot(type %in% c("capital", "cent", "min"))

  # Read in the RDS file for the type and year
  matrix.raw <- readRDS(file.path(distance.folder,
                                  paste0(type, "_", year, "-01-01.rds")))

  # Convert distance matrix to long dataframe
  df.clean <- as.data.frame(matrix.raw) %>%
    mutate(gwcode = rownames(.)) %>%
    gather(gwcode.other, distance, -gwcode) %>%
    # Set inverted diagonal 0s to 0, real 0s to 1
    mutate(distance.inv = ifelse(gwcode == gwcode.other & distance == 0, 0,
                                 ifelse(gwcode != gwcode.other & distance == 0, 1,
                                        1 / distance))) %>%
    mutate(type = type, year = year) %>%
    mutate_each(funs(as.numeric), starts_with("gwcode")) %>%
    # Mark if country is within 900 km
    mutate(is.rough.neighbor = distance < 900) %>%
    # Standardize inverted distances so that all rows within a country add to 1
    # so that it can be used in weighted.mean.
    # This is the same as calculating the row sum of the matrix
    group_by(gwcode) %>%
    mutate(distance.std = distance.inv / sum(distance.inv)) %>%
    ungroup() %>%
    left_join(gw.codes, by="gwcode") %>%
    left_join(gw.codes, by=c("gwcode.other"="gwcode"),
              suffix=c(".self", ".other"))

  return(df.clean)
}

# Load and combine all distance matrices
all.distances <- expand.grid(year = 2012,
                             type = c("capital", "cent", "min"),
                             stringsAsFactors=FALSE) %>%
  rowwise() %>% do(read_distances(.$type, .$year)) %>% ungroup()

all.distances %>% glimpse()
```


## Quality of governance

V-Dem or QoG


## Other controls

### World Bank development indicators

The World Bank has a fantastic API for [their statistical indicators](http://data.worldbank.org/) and there's already [a nice R package](https://cran.r-project.org/package=WDI) for accessing it, so downloading indicators is trivial. For the sake of our models, we care about GDP per capita as a proxy for a country's overall development. We also collect a few other relevant variables just for fun.

```{r load-wdi, cache=TRUE}
wdi.indicators <- c("NY.GDP.PCAP.KD",        # GDP per capita (constant 2010 USD)
                    "NY.GDP.MKTP.KD",        # GDP (constant 2010 USD)
                    "SP.POP.TOTL",           # Population, total
                    "BX.KLT.DINV.WD.GD.ZS")  # Foreign direct investment, net inflows (% of GDP)

# Get all countries and regions because the World Bank chokes on ISO codes like
# XK for Kosovo, even though it returns data for Kosovo with the XK code
# ¯\_(ツ)_/¯
wdi.raw <- WDI(country="all", wdi.indicators,
               extra=FALSE, start=1980, end=2015)

# Filter countries here instead
wdi.clean <- wdi.raw %>%
  filter(iso2c %in% unique(gw.codes$iso2)) %>%
  arrange(iso2c, year) %>%
  rename(gdp.capita = NY.GDP.PCAP.KD, gdp = NY.GDP.MKTP.KD,
         population = SP.POP.TOTL, fdi.in.pct.gdp = BX.KLT.DINV.WD.GD.ZS) %>%
  mutate_at(vars(gdp.capita, gdp, population), funs(log=log1p)) %>%
  left_join(select(gw.codes, iso2, cowcode), by=c("iso2c" = "iso2"))

wdi.clean %>% head(100) %>% datatable(extensions="Responsive")

wdi.clean %>% glimpse()
```


### Former colonial status

[Paul Hensel has collected data](http://www.paulhensel.org/icowcol.html) on each country's former colonial status, indicating both a given country's primary colonial ruler and the last colonial ruler prior to independence. The dataset also includes an estimated date of independence.

Colonial status could matter for aid, with donor countries favoring former colonies (i.e. France might be more likely to donate to former African colonies; Spain might be more likely to donate to Latin America; etc.)

Because there are so many columns, the data below has been horizontally collapsed—click on the green plus sign to see the rest of the data in a row.

```{r load-colonial-status, message=FALSE, cache=TRUE}
col.url <- "http://www.paulhensel.org/Data/colhist.zip"
col.path <- file.path(PROJHOME, "Data", "data_raw")
col.zip.name <- basename(col.url)
col.name <- tools::file_path_sans_ext(col.zip.name)

col.final.name <- "coldata100.csv"
col.full.path <- file.path(col.path, "ICOW Colonial History 1.0", 
                           col.final.name)

# Download ICOW data if needed
if (!file.exists(col.full.path)) {
  col.get <- GET(col.url, 
                 write_disk(file.path(col.path, col.zip.name),
                            overwrite=TRUE), 
                 progress())
  unzip(file.path(col.path, col.zip.name), exdir=col.path)
  
  file.remove(file.path(col.path, col.zip.name))
}

col.raw <- read_csv(col.full.path, na="-9",
                    col_types=cols(
                      State = col_integer(),
                      Name = col_character(),
                      ColRuler = col_integer(),
                      IndFrom = col_integer(),
                      IndDate = col_integer(),
                      IndViol = col_integer(),
                      IndType = col_integer(),
                      SecFrom = col_integer(),
                      SecDate = col_integer(),
                      SecViol = col_integer(),
                      Into = col_integer(),
                      IntoDate = col_integer(),
                      COWsys = col_integer(),
                      GWsys = col_integer(),
                      Notes = col_character()
                    )) 

col.clean <- col.raw %>%
  # Independence dates with unknown months are coded as 00, which makes
  # lubridate choke. So change those to 01
  mutate(IndDate.clean = str_replace(IndDate, "00$", "01")) %>%
  # Years less than 1000 make lubridate choke, so preface them with a 0
  mutate(IndDate.clean = ifelse(nchar(IndDate.clean) == 5, 
                                paste0(0, IndDate.clean), IndDate.clean)) %>%
  mutate(IndDate = ymd(paste0(IndDate.clean, "01"))) %>%
  left_join(select(gw.codes, iso3, cowcode, country.name),
            by=c("State" = "cowcode")) %>%
  left_join(select(gw.codes, col.ruler.cowcode = cowcode, 
                   col.ruler.iso3 = iso3, 
                   col.ruler.country.name = country.name),
            by=c("ColRuler" = "col.ruler.cowcode")) %>%
  left_join(select(gw.codes, ind.from.cowcode = cowcode,
                   ind.from.iso3 = iso3, 
                   ind.from.country.name = country.name),
            by=c("IndFrom" = "ind.from.cowcode")) %>%
  select(cowcode = State, country.name, col.ind.date = IndDate,
         col.ruler.country.name, col.ruler.cowcode = ColRuler, col.ruler.iso3,
         ind.from.country.name, ind.from.cowcode = IndFrom, ind.from.iso3) %>%
  # Get rid of smaller ancient states like Tuscany, Parma, and Zanzibar
  filter(!is.na(country.name))

col.clean %>% datatable(extensions="Responsive")

col.clean %>% glimpse()
```


### Natural disasters

Natural disaster data comes from the [International Disaster Database (EM-DAT)](http://www.emdat.be/database). The data includes the number of deaths, injuries, homeless displacements, and monetary losses (in 2000 dollars) for a huge number of natural and technological disasters (see [EM-DAT's full classification](http://www.emdat.be/classification)).

Natural disasters could matter for aid too, since donor countries might increase their aid to countries suffering more. 

EM-DAT does not provide a single link to download their data. Instead, you have to create a query using [their advanced search form](http://www.emdat.be/advanced_search/index.html). We downloaded data using the following query:

- Select all countries from up to 2016
- Select all three disaster classification groups (natural, technological, complex)
- Group results by country name, year, and disaster type
- Download CSV and save in `PROJHOME/Data/data_raw/Disasters/Data.csv`


```{r load-disasters, message=FALSE}
# Disaster classification
disaster.classification.raw <- "http://www.emdat.be/classification" %>%
  read_html() %>%
  html_nodes(xpath='//*[@id="article-14627"]/div/div/div/div/table[1]') %>%
  html_table(header=TRUE)

# For whatever reason, the downloaded data treats technological subgroups as
# main types (e.g. "industrial accident" is listed as a disaster type, not
# "chemical spill" or "fire" or whatever). So, make a new column of the actual
# disaster type using the real type for natural disasters and the subgroup for
# non-natural disasters.
#
# Also, add a couple rows for complex and miscellaneous disasters
disaster.classification <- disaster.classification.raw[[1]] %>%
  select(-Definition) %>%
  mutate_all(funs(str_trim(str_to_lower(.)))) %>%
  # Fix typo
  mutate(`Disaster Subgroup` = ifelse(`Disaster Subgroup` == "miscelleanous accident",
                                      "miscellaneous accident", `Disaster Subgroup`)) %>%
  mutate(`Actual Type` = ifelse(`Disaster Group` == "natural", 
                                `Disaster Main Type`, `Disaster Subgroup`)) %>%
  distinct(`Disaster Group`, `Disaster Subgroup`, `Actual Type`) %>%
  bind_rows(tribble(
    ~`Disaster Group`, ~`Disaster Subgroup`, ~`Actual Type`,
    "complex",         "complex disasters",  "complex disasters"
  ))

# Disaster data
# http://www.emdat.be/advanced_search/index.html

# Select all countries from whenever to 2016
# Select all three disaster classification groups (natural, technological, complex)
# Group results by country name, year, and disaster type
# Download CSV and save in PROJHOME/Data/data_raw/Disasters

disasters.raw <- read_csv(file.path(PROJHOME, "Data", "data_raw", 
                                    "Disasters", "data.csv"),
                          skip=1)  # First row is junk

# Read in disaster data and join with classification data
disasters <- disasters.raw %>%
  mutate(`disaster type` = str_trim(str_to_lower(`disaster type`))) %>%
  mutate(`disaster type` = ifelse(`disaster type` == "mass movement (dry)",
                                  "mass movement", `disaster type`)) %>%
  left_join(disaster.classification, by=c("disaster type"="Actual Type")) %>%
  mutate(iso = str_to_upper(iso), 
         cowcode = countrycode(iso, "iso3c", "cown")) %>%
  mutate(cowcode = case_when(
    .$iso == "HKG" ~ as.integer(715),
    .$iso == "DFR" ~ as.integer(255),
    .$iso == "PSE" ~ as.integer(669),
    .$iso == "SUN" ~ as.integer(365),
    .$iso == "YMN" ~ as.integer(679),
    .$iso == "SRB" ~ as.integer(340),
    .$iso == "SCG" ~ as.integer(345),
    TRUE ~ .$cowcode
  )) %>%
  # Get rid of tiny countries
  filter(!is.na(cowcode)) %>%
  # Fix missing names (collapsing old Germanies, Yemens, and USSR)
  mutate(country_name = countrycode(iso, "iso3c", "country.name")) %>%
  mutate(country_name = case_when(
    .$iso == "DFR" ~ "Germany",
    .$iso == "SCG" ~ "Yugoslavia",
    .$iso == "SUN" ~ "Russia",
    .$iso == "YMN" ~ "Yemen",
    TRUE ~ country_name
  )) %>%
  # Fix ISOs
  mutate(iso = countrycode(country_name, "country.name", "iso3c")) %>%
  select(country_name, year, iso3 = iso, cowcode, disaster.type = `disaster type`, 
         disaster.group = `Disaster Group`, disaster.subgroup = `Disaster Subgroup`,
         disaster.occurrence = occurrence, disaster.deaths = `Total deaths`,
         disaster.injured = `Injured`, disaster.affected = `Affected`,
         disaster.homeless = `Homeless`, disaster.total.affected = `Total affected`,
         disaster.total.damage = `Total damage`) %>%
  filter(disaster.group != "complex")
```

```{r}
# Summarize disaster variables by country, year, and type/group/subgroup
disaster.vars <- vars(disaster.occurrence, disaster.deaths, disaster.injured, 
                      disaster.affected, disaster.homeless, disaster.total.affected,
                      disaster.total.damage)

disasters.groups <- disasters %>%
  group_by(cowcode, year, disaster.group) %>%
  summarise_at(disaster.vars, funs(sum(., na.rm=TRUE))) %>%
  ungroup() %>%
  gather(key, value, disaster.occurrence, disaster.deaths, disaster.injured, 
                      disaster.affected, disaster.homeless, disaster.total.affected,
                      disaster.total.damage) %>%
  unite(key, disaster.group, key) %>%
  spread(key, value) %>%
  filter(year > 1980, year < 2016)

disasters.groups %>% head(100) %>% datatable(extensions="Responsive")
```

```{r}
disasters.groups %>% glimpse()
```


## Final clean combined data

With both donor- and country-level data, we have lots of different options for analysis. Since our hypotheses deal with questions of *donor* responses, the data we use to model donor responses uses donor-years as the unit of observation. Not all donors give money to the same countries, so this final data is not a complete panel (i.e. it does not include every combination of donors and years), which will pose some interesting methodological issues when modeling.

```{r build-final-data}
# Donor data
donor.level.data <- aiddata.final %>%
  filter(cowcode %in% dcjw.full$cowcode) %>%
  filter(year > 1980) %>%
  filter(oda > 0) %>%  # Only look at positive aid
  mutate(oda_log = log1p(oda))

# TODO: Indicator for changes in laws, year since change

# TODO: Aid by scope (domestic NGO vs. international NGO)
# donor.level.data.us <- usaid.clean

# TODO: Aid to neighboring countries

# Country data
# Use DCJW 1980+ as base data, since we're limited to the countries included there
country.level.data <- dcjw.full %>%
  left_join(select(vdem.cso, year, cowcode, csre), by=c("cowcode", "year")) %>%
  # TODO: Quality of governance + Polity stuff
  left_join(select(wdi.clean, -c(iso2c, country)), by=c("cowcode", "year")) %>%
  left_join(select(col.clean, -country.name), by=c("cowcode")) %>%
  left_join(select(disasters.groups, cowcode, year, starts_with("natural_")), 
            by=c("cowcode", "year")) %>%
  # NAs in disasters are really 0, especially when occurrence is 0
  mutate_at(vars(starts_with("natural_")), funs(ifelse(is.na(.), 0, .)))
testthat::expect_equal(nrow(country.level.data), nrow(dcjw.full))

# Combine country and donor data
donor.country.data <- donor.level.data %>%
  left_join(select(country.level.data, -country.name), by=c("year", "cowcode")) %>%
  mutate(former.colony = donor.iso3 == col.ruler.iso3 | 
           donor.iso3 == ind.from.iso3) %>%
  arrange(donor, year)
testthat::expect_equal(nrow(donor.country.data), nrow(donor.level.data))

donor.country.data %>% head(100) %>% datatable(extensions="Responsive")

donor.country.data %>% glimpse()
```

### Missingness in final data

This data is relatively complete, with only a few variables suffering from missing data. The worst offenders are the DCJW laws, which we conservatively left as missing if the law never appears as 0 or 1 in the data. If we assume that the missingness of a law indicates its absence, those variables will be far more complete.

```{r final-data-missing, fig.width=6, fig.height=4.5}
percent.missing <- donor.country.data %>%
  mutate_all(funs(is.na(.))) %>%
  gather(variable, value) %>%
  group_by(variable) %>%
  summarise(perc.missing = sum(value) / n()) %>%
  ungroup() %>%
  mutate(variable = factor(variable, levels=rev(colnames(donor.country.data)),
                           ordered=TRUE)) %>%
  arrange(desc(variable)) %>%
  mutate(row.name = 1:n())

# Split into columns because there are so many variables
n.cols <- 2
perc.missing.rows <- 1:nrow(percent.missing)
perc.missing.cols <- split(perc.missing.rows,
                           cut(perc.missing.rows,
                               quantile(perc.missing.rows, (0:n.cols) / n.cols),
                               include.lowest=TRUE, labels=FALSE)) %>%
  as_data_frame() %>% gather(column, row.name)

percent.missing <- percent.missing %>%
  left_join(perc.missing.cols, by="row.name")

ggplot(percent.missing, aes(x=perc.missing, y=variable)) +
  geom_barh(stat="identity") + 
  scale_x_continuous(labels=scales::percent, limits=c(0, 1)) + 
  labs(x="Percent missing", y=NULL) + 
  facet_wrap(~ column, nrow=1, scales="free_y") +
  theme_donors() + theme(strip.text=element_blank())
```
