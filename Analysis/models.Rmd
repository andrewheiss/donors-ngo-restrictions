---
title: "Models"
author: "Suparna Chaudhry and Andrew Heiss"
date: "`r format(Sys.time(), '%B %e, %Y')`"
output: 
  html_document: 
    code_folding: hide
    css: ../html/fixes.css
    fig_height: 3.5
    fig_width: 5
    highlight: pygments
    includes:
      after_body: ../html/add_home_link.html
    theme: spacelab
    toc: yes
    toc_depth: 4
    toc_float: yes
---

```{r load-libraries, message=FALSE}
knitr::opts_chunk$set(cache=FALSE, fig.retina=2,
                      tidy.opts=list(width.cutoff=120),  # For code
                      options(width=120))  # For output

library(tidyverse)
library(stringr)
library(forcats)
library(stargazer)
library(lme4)
library(modelr)
library(broom)

source(file.path(PROJHOME, "lib", "graphics.R"))
source(file.path(PROJHOME, "lib", "pandoc.R"))
source(file.path(PROJHOME, "lib", "bayes.R"))

source(file.path(PROJHOME, "Analysis", "robustness_models_definitions.R"))
source(file.path(PROJHOME, "Analysis", "h1_model_definitions.R"))

my.seed <- 1234
set.seed(my.seed)

run.rstan <- FALSE
```

```{r load-data, cache=TRUE, message=FALSE}
df.country.aid <- readRDS(file.path(PROJHOME, "Data", "data_clean",
                                "df_country_aid_no_imputation.rds"))

df.country.aid.impute <- readRDS(file.path(PROJHOME, "Data", "data_clean",
                                           "df_country_aid_imputation.rds"))

df.country.aid.impute.m10 <- readRDS(file.path(PROJHOME, "Data", "data_clean",
                                               "df_country_aid_imputation_m10.rds"))

dcjw.questions.clean <- read_csv(file.path(PROJHOME, "Data", "data_clean",
                                           "dcjw_questions.csv"))
dcjw.responses.clean <- read_csv(file.path(PROJHOME, "Data", "data_clean",
                                           "dcjw_responses.csv"))

# Load clean coefficient names and append "within" and "between" to them,
# resulting in a giant table of possible coefficient names
coef.names <- read_csv(file.path(PROJHOME, "Data", "data_clean",
                                 "coef_names.csv"))

coef.names.within <- coef.names %>%
  mutate(term = paste0(term, "_within"),
         term_clean = paste0(term_clean, "~within~"))

coef.names.between <- coef.names %>%
  mutate(term = paste0(term, "_between"),
         term_clean = paste0(term_clean, "~between~"))

coef.names.all <- bind_rows(coef.names, coef.names.within, coef.names.between)


# Combine original data and imputed data so calculations can happen at the same time
df.country.aid.both <- bind_rows(df.country.aid, df.country.aid.impute)

# Combine m=10 imputated data too since we use it in some robustness checks.
# Imputations 6-10 are later removed
df.country.aid.all <- bind_rows(df.country.aid, df.country.aid.impute.m10)

# All the missing values have been taken care of, but final years for leaded
# variables *are* still missing (i.e. there's no aid data for 2014, so
# total.oda_log_next_year will be NA in 2013). For this fancy random effects
# regression to work, the demeaned variables have to be based on the means of
# all rows included in the regression, so they can't include rows that are
# dropped because of missingness. This means we have to make separate demeaned
# datasets for *_after_2 and *_after_5, but ¯\_(ツ)_/¯
df.country.aid.demean.next_year.all <- df.country.aid.all %>%
  filter(!is.na(total.oda_log_next_year)) %>%
  group_by(m, cowcode) %>%
  mutate_at(vars(barriers.total, advocacy, entry, funding, 
                 polity, gdp.capita_log, gdp.capita, trade.pct.gdp, corruption, csre,
                 total.oda_log),
            funs(between = mean(., na.rm=TRUE),  # meaned
                 within = . - mean(., na.rm=TRUE))) %>%  # demeaned
  ungroup()

# Divide demeaned data into separate data frames: original, imputed (m=5), and imputed (m=10)
df.country.aid.demean.next_year.both <- 
  filter(df.country.aid.demean.next_year.all, !(m %in% paste0("imp", 6:10)))

df.country.aid.demean.next_year <- 
  filter(df.country.aid.demean.next_year.all, m == "original")

df.country.aid.demean.next_year.impute <- 
  filter(df.country.aid.demean.next_year.all, 
         m != "original", !(m %in% paste0("imp", 6:10)))

df.country.aid.demean.next_year.impute.m10 <- 
  filter(df.country.aid.demean.next_year.all, m != "original")

# Demean data with total.oda_log leaded by 2 years and 5 years
# After 2 years
df.country.aid.demean.after_2.both <- df.country.aid.both %>%
  filter(!is.na(total.oda_log_after_2)) %>%
  group_by(m, cowcode) %>%
  mutate_at(vars(barriers.total, advocacy, entry, funding, 
                 polity, gdp.capita_log, gdp.capita, trade.pct.gdp, corruption, csre,
                 total.oda_log),
            funs(between = mean(., na.rm=TRUE),  # meaned
                 within = . - mean(., na.rm=TRUE))) %>%  # demeaned
  ungroup()

df.country.aid.demean.after_2 <- 
  filter(df.country.aid.demean.after_2.both, m == "original")

df.country.aid.demean.after_2.impute <- 
  filter(df.country.aid.demean.after_2.both, m != "original")

# After 5 years
df.country.aid.demean.after_5.both <- df.country.aid.both %>%
  filter(!is.na(total.oda_log_after_5)) %>%
  group_by(m, cowcode) %>%
  mutate_at(vars(barriers.total, advocacy, entry, funding, 
                 polity, gdp.capita_log, gdp.capita, trade.pct.gdp, corruption, csre,
                 total.oda_log),
            funs(between = mean(., na.rm=TRUE),  # meaned
                 within = . - mean(., na.rm=TRUE))) %>%  # demeaned
  ungroup()

df.country.aid.demean.after_5 <- 
  filter(df.country.aid.demean.after_5.both, m == "original")

df.country.aid.demean.after_5.impute <- 
  filter(df.country.aid.demean.after_5.both, m != "original")
```

```{r helpful-functions}
stars <- function(p) {
  out <- symnum(p, cutpoints=c(0, 0.01, 0.05, 0.1, 1),
                symbols=c("***", "**", "*", ""))
  as.character(out)
}

fixed.digits <- function(x, n=2) {
  formatC(x, digits=n, format="f")
}

# Take apart the pieces of a random effects formula and rebuild it
build.formula <- function(DV, IVs) {
  terms.all <- attr(terms(IVs), "term.labels")
  terms.fixed <- terms.all[!stringr::str_detect(terms.all, "\\|")]
  terms.rand <- sapply(findbars(formula(IVs)),function(x) paste0("(", deparse(x), ")"))
  
  reformulate(c(terms.fixed, terms.rand), response=DV)
}

# Meld a bunch of imputed models
meld.imputed.models <- function(model.data) {
  models.df <- model.data$glance[[1]]$df.residual
  
  models.tidy <- model.data %>%
    select(tidy) %>%
    unnest(.id="imputation")
  
  just.estimates <- models.tidy %>% 
    filter(group == "fixed") %>%
    select(imputation, term, estimate) %>%
    spread(term, estimate) %>%
    select(-imputation)
  
  just.ses <- models.tidy %>%
    filter(group == "fixed") %>%
    select(imputation, term, std.error) %>%
    spread(term, std.error) %>%
    select(-imputation)

  # If no imputed data was passed in, use the actual estimates and SEs
  if (nrow(just.estimates) > 1) {
    melded <- Amelia::mi.meld(just.estimates, just.ses)
  } else {
    melded <- list(q.mi = just.estimates, se.mi = just.ses)
  }

  melded.tidy <- as.data.frame(cbind(t(melded$q.mi), 
                                     t(melded$se.mi))) %>%
    magrittr::set_colnames(c("estimate", "std.error")) %>%
    mutate(term = rownames(.)) %>%
    select(term, everything()) %>%
    mutate(statistic = estimate / std.error,
           conf.low = estimate + std.error * qt(0.025, models.df),
           conf.high = estimate + std.error * qt(0.975, models.df),
           p.value = 2 * pt(abs(statistic), models.df, lower.tail=FALSE),
           stars = stars(p.value))  
  melded.tidy
}

# Expects a data frame with a column named tidy.melded and a row for model
# names. Term names are based on the first model in the data column for each
# row, and are filtered through stargazer to get the correct row order.
stargazer.fake <- function(df) {
  # Create a blank row with a bolded row name
  header.row <- function(header) {
    data_frame(term = paste0("**", header, "**"), 
               models = df$model.name, value = "") %>%
    spread(models, value)
  }
  
  coef.order.models <- df %>%
    # Select just the first row of each model
    unnest(data) %>%
    # Sometimes there are duplicate column names
    # magrittr::set_colnames(make.unique(colnames(.))) %>%
    # Keep order of model.name
    mutate(model.name = ordered(fct_inorder(model.name))) %>%
    group_by(model.name) %>%
    slice(1) %>% ungroup() %>%
    select(model) %>% as.list()
  
  # Use stargazer to get the coefficient order. I tried recreating stargazer's
  # coefficient ordering algorithm but it's way too complicated. So instead, we
  # cheat and let stargazer do the heavy lifting, save the output to a string,
  # and then extract the coefficient names with str_extract. Super super hacky,
  # but it works.
  #
  # See http://stackoverflow.com/a/41801861/120898
  capture.output({
    stargazer.coefs <- stargazer::stargazer(coef.order.models, 
                                            type="text", table.layout="t")
  }, file="/dev/null")
  
  coef.order <- setdiff(stringr::str_extract(stargazer.coefs, "^[\\w\\.]*"), c(""))
  
  # Fixed parts
  fixed.coefs <- df %>%
    unnest(tidy.melded) %>%
    mutate(fancy = paste0(fixed.digits(estimate, 3),
                          stars, "\\ \n(",
                          fixed.digits(std.error, 3),
                          ")")) %>%
    select(model.name, term, fancy) %>%
    spread(model.name, fancy, fill="") %>%
    # Clean up term names
    mutate(term = stringr::str_replace(term, "TRUE$|FALSE$", ""),
           term = recode(term, `(Intercept)` = "Constant")) %>%
    # Use stargazer's coefficient order
    mutate(term = factor(term, levels=coef.order, ordered=TRUE)) %>%
    arrange(term) %>%
    mutate(term = as.character(term)) %>%
    left_join(coef.names.all, by="term") %>%
    mutate(term_clean = ifelse(term == "Constant", "Constant", term_clean)) %>%
    select(-term) %>% rename(term = term_clean) %>%
    select_(.dots = c("term", df$model.name))
  
  # Random parts
  random.coef.order.raw <- df %>%
    unnest(data) %>%
    # unnest(data) %>% magrittr::set_colnames(make.unique(colnames(.))) %>%
    select(model.name, model) %>%
    mutate(ranef = model %>% map(~ as.data.frame(VarCorr(.)))) %>%
    unnest(ranef)
  random.coef.order <- c(setdiff(unique(random.coef.order.raw$grp), "Residual"), "Residual")
  
  random.coefs <- df %>%
    unnest(data) %>%
    unnest(tidy) %>%
    filter(group != "fixed") %>%
    rename(term.raw = term, term = group) %>%
    group_by(model.name, term) %>%
    summarise(avg.random.sd = mean(estimate),
              sd.random.sd = sd(estimate)) %>%
    mutate(fancy = paste0(fixed.digits(avg.random.sd, 3),
                          "\\ \n(",
                          ifelse(is.na(sd.random.sd), "NA", fixed.digits(sd.random.sd, 3)),
                          ")")) %>%
    select(model.name, term, fancy) %>%
    spread(model.name, fancy, fill="") %>%
    mutate(term = factor(term, levels=random.coef.order, ordered=TRUE)) %>%
    arrange(term) %>% mutate(term = as.character(term)) %>%
    left_join(coef.names.all, by="term") %>%
    mutate(term_clean = ifelse(term == "Residual", 
                               "Residual random error ($\\sigma$)", term_clean)) %>%
    select(-term) %>% select(term=term_clean, everything())

  # Create the bottom half of the table
  # Calculate the average log likelihood for all imputed models
  avg.loglik <- df %>%
    unnest(data) %>% unnest(glance) %>%
    group_by(model.name) %>%
    summarise(avg.loglik = as.character(round(mean(logLik), 2))) %>%
    mutate(term = "Log likelihood (mean)") %>%
    spread(model.name, avg.loglik)

  # Imputation frames
  n.obs <- df %>%
    unnest(data) %>%
    mutate(n = model %>% map_int(~ nrow(.@frame))) %>%
    select(model.name, n) %>%
    group_by(model.name) %>% slice(1) %>% ungroup() %>%
    mutate(term = "Observations",
           n = scales::comma(n)) %>%
    spread(model.name, n)
  
  n.m <- df %>%
    mutate(m.new = data %>% map_int(~ nrow(.))) %>%
    select(model.name, m.new) %>% 
    mutate(m.new = ifelse(m.new == 1, 0, m.new),
           m.new = as.character(m.new)) %>%
    mutate(term = "Imputated datasets (*m*)") %>%
    spread(model.name, m.new)

  bottom.details <- bind_rows(n.obs, avg.loglik, n.m)

  nice.top.bottom <- bind_rows(header.row("Fixed part"), fixed.coefs, 
                               header.row("Random part"), random.coefs,
                               header.row("Model details"), bottom.details) %>%
    select_(.dots = c("term", df$model.name))
  
  # Make column names (1), (2), etc.
  # TODO: Allow for custom column names
  colnames(nice.top.bottom) <- c("", paste0("(", 1:length(df$model.name), ")"))
  
  # All columns are centered except the first
  # TODO: MAYBE: Let this be user configurable
  table.align <- paste0(c("l", rep("c", length(df$model.name))), collapse="")
  
  pandoc.table(nice.top.bottom, keep.line.breaks=TRUE, justify=table.align)
}
```

## General model specifications and controls

We use a standard set of controls in each model ([explained in more detail here](../Data/get_merge_data.html#other_controls_and_alternative_hypotheses)):

- Democracy: `polity`
- Wealth: `gdp.capita_log` (logged so it's on the same scale as the other variables) 
- Government capacity: `corruption`
- Bad stuff: `internal.conflict.past.5` and `natural_disaster.occurrence`

Following [Bell and Jones (2015)](http://dx.doi.org/10.1017/psrm.2014.7), we use crossed random effects for country and year and use a combination of meaned and demeaned versions of each continuous variable to estimate both the within and between effects of each variable. 

$$ y_{i, t + 1} = \beta_0 + \beta_1 (x_{it} - \bar{x}_i) + \beta_2 \bar{x}_i + \ldots $$

This approach has multiple benefits. The coefficients for the demeaned variables are roughly equivalent to their corresponding coefficeints in a fixed effects model, but a fixed effects model assumes that the between effect (captured by the mean variables) is 0, which is not the case. A random effects model specified in this manner is more interpretable, as it clearly separates the within and between effects (again, within = demeaned, between = mean).

Here's proof of how it works in some simple models. Model 1 is a basic OLS with country fixed effects. Model 2 is a basic OLS with country random effects, but potentially misspecified, since the between and within effects are conflated. Model 3 is a basic OLS with country random effects specified with between (mean; $\bar{x}_i$) and within (demeaned; $x_{it} - \bar{x}_i$) coefficients. The demeaned/within coefficients in Model 3 are identical to the fixed effects coefficients in Model 1. If rows had been dropped because of listwise deletion (like, if there were missing values in one of independent variables), the coefficients would be slightly off, since the demeaned values would have been based on group means that included the values that were dropped (e.g. all 2013 rows are dropped because of lags, but the group means included 2013). This isn't  a problem in these reduced models, but that's one reason we impute all the data—we need the data to be as complete as possible to get the most accurate random effects.

```{r fixed-random-example, results="asis"}
mod.test.fe <- lm(total.oda_log_next_year ~ 
                    barriers.total + polity + gdp.capita_log + 
                    as.factor(cowcode),
                  data=df.country.aid.demean.next_year)

mod.test.re <- lmer(total.oda_log_next_year ~ 
                    barriers.total + polity + gdp.capita_log + 
                    (1 | cowcode),
                  data=df.country.aid.demean.next_year)

mod.test.re.fancy <- lmer(total.oda_log_next_year ~ 
                            barriers.total_between + barriers.total_within +
                            polity_between + polity_within + 
                            gdp.capita_log_between + gdp.capita_log_within +
                            (1 | cowcode),
                          data=df.country.aid.demean.next_year)

stargazer(mod.test.fe, mod.test.re, mod.test.re.fancy,
          type="html", omit="factor", 
          add.lines=list(c("Country effects",
                           c("Fixed", "Random", "Random"))),
          keep.stat=c("n"))
```


## H~1~: Donors reduce aid in response to legislation

> **H~1~**: In response to restrictive NGO legislation, bilateral, multilateral, and private donors may reduce their aid to repressive countries.

$$ln( \text{ODA} )_{i, t+1} = \text{NGO legislation}_{it} + \text{controls}_{it}$$

Our dependent variable for this hypothesis is the log of ODA (constant 2011 dollars), leaded by one year so we don't have to lag every other independent variable. As a robustness check, we also include models with log ODA leaded by 2 years and 5 years to account the implementation period following the passage of a law.

We look at NGO legislation in a few different ways:

- `barriers.total`: Number of anti-NGO legal barriers in a country-year
- `barriers.total_new`: Indicator marking if a new anti-NGO barrier was passed in a country year
- `advocacy + entry + funding`: Number of anti-NGO legal barriers by type of barrier
- `advocacy_new + entry_new + funding_new`: Indicators marking new type of barrier
- `csre`: Civil society regulatory environment index (CSRE), ranging from roughly -4 to 4 (higher values = better civil society regulations)

```{r h1-models-1, warning=FALSE, message=FALSE, cache=TRUE}
# Run models on each of the datasets (original and imputed) and save in a big data frame
mods.h1.next_year.raw <- df.country.aid.demean.next_year.both %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total,
                                              "total.oda_log_next_year"),
         mod.h1.barriers.new = data %>% map(mod.h1.barriers.new,
                                            "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total,
                                          "total.oda_log_next_year"),
         mod.h1.type.new = data %>% map(mod.h1.type.new,
                                        "total.oda_log_next_year"),
         mod.h1.csre = data %>% map(mod.h1.csre,
                                    "total.oda_log_next_year"))

# Get model details and parameters
mods.h1.next_year <- mods.h1.next_year.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int=TRUE),
         augment = model %>% map(broom::augment))

# Meld the imputed models
mods.h1.next_year.melded <- mods.h1.next_year %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

```{r h1-models-bayes-1, warning=FALSE, message=FALSE}
if (run.rstan) {
  source(file.path(PROJHOME, "Analysis", "h1_model_definitions_bayes.R"))
  
  mods.h1.next_year.raw.bayes <- df.country.aid.demean.next_year %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total.bayes,
                                              "total.oda_log_next_year"),
         mod.h1.barriers.new = data %>% map(mod.h1.barriers.new.bayes,
                                            "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total.bayes,
                                          "total.oda_log_next_year"),
         mod.h1.type.new = data %>% map(mod.h1.type.new.bayes,
                                        "total.oda_log_next_year"),
         mod.h1.csre = data %>% map(mod.h1.csre.bayes,
                                    "total.oda_log_next_year"))
}
```

### Results

#### Imputed and melded frequentist models

All of these models use imputed data ($m = 5$) with crossed year and country random effects.

The $\sigma$ value for within-country variability here is 0, which is a side effect of controlling for the amount of aid in the current year. When $\sigma = 0$, the between-group variability is too small to fully account for between effects, resulting in a "degenerate model" (see [pages 10–11 here](http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf)). Despite how scary that sounds, these kinds of models are allowed; according to Bates (2010), "degenerate models can and do occur in practice." The other coefficents in the model appear to be well-estimated, so we live with the model's degeneracy. 

```{r h1-melded-table-1, results="asis", warning=FALSE}
stargazer.fake(mods.h1.next_year.melded)
```

### Predicted ODA

**THIS IS ALL WRONG DISREGARD**

`barriers.total_between` is significant at the 95% level in the first model, and it's substantially so. The grey band below indicates the 90% prediction interval, calculated with 1000 simulated draws from model results (these intervals are waaaay too big for now; they'll be more accurate when running the Bayesian models). One additional anti-NGO law is associated with a 36% increase in ODA in the following year *between* countries in the panel.

```{r h1-visualize, warning=FALSE}
# model.to.use <- mods.h1.next_year %>%
#   filter(m == "original", model.name == "mod.h1.barriers.total")
# 
# model.to.use <- model.to.use$model[[1]]
# 
# new.data <- model.to.use@frame %>%
#   select(-barriers.total_between) %>%
#   summarise_all(typical) %>%
#   mutate(id = 1) %>%
#   right_join(expand.grid(barriers.total_between = seq(0, 12, 0.1),
#                          id = 1), by="id")
# 
# plot.predict <- merTools::predictInterval(merMod=model.to.use, newdata=new.data, 
#                                           level=0.90, n.sims=1000,
#                                           stat="median", type="linear.prediction",
#                                           include.resid.var=TRUE) %>%
#   rename(pred = fit, pred.upper = upr, pred.lower = lwr) %>%
#   bind_cols(augment(model.to.use, newdata=new.data))
# 
# ggplot(plot.predict, aes(x=barriers.total_between, y=.fitted)) + 
#   geom_line() + 
#   geom_ribbon(aes(ymin=pred.lower, ymax=pred.upper),
#               alpha=0.3, colour=NA) + 
#   labs(x="Total barriers (between; average value for each country)", y="Predicted log ODA") +
#   theme_donors()
```

Looking at the overall effect of the civil society regulatory environment, though, does yield a significant effect. A one point increase in the CSRE is associated with a 41% increase in ODA in the following year (and vice versa; worsening CSRE leads to a reduction in aid) *within* countries in the panel.

```{r h1-visualize1, warning=FALSE}
# model.to.use <- mods.h1.next_year %>%
#   filter(m == "original", model.name == "mod.h1.csre")
# 
# model.to.use <- model.to.use$model[[1]]
# 
# new.data <- model.to.use@frame %>%
#   select(-csre_within) %>%
#   summarise_all(typical) %>%
#   mutate(id = 1) %>%
#   right_join(expand.grid(csre_within = seq(-4, 4, 0.1),
#                          id = 1), by="id")
# 
# plot.predict <- merTools::predictInterval(merMod=model.to.use, newdata=new.data, 
#                                           level=0.90, n.sims=1000,
#                                           stat="median", type="linear.prediction",
#                                           include.resid.var=TRUE) %>%
#   rename(pred = fit, pred.upper = upr, pred.lower = lwr) %>%
#   bind_cols(augment(model.to.use, newdata=new.data))
# 
# ggplot(plot.predict, aes(x=csre_within, y=.fitted)) + 
#   geom_line() + 
#   geom_ribbon(aes(ymin=pred.lower, ymax=pred.upper),
#               alpha=0.3, colour=NA) + 
#   labs(x="CSRE (within; difference from mean)", y="Predicted log ODA") +
#   theme_donors()
```

## Robustness checks

### Imputation

[As discussed over in the data cleaning file](../Data/get_merge_data.html#missingness_and_imputation), we impute data for the few variables that are missing. To show what difference imputation makes, the table below shows three pairs of models from H~1~. The first two models are run on non-imputed data (so missing observations are deleted listwise), the second two models are run on 5 sets of imputed data, and the last two models are run on 10 sets of imputed data. 

It's clear that imputation makes a substantial difference—note the big differences between coefficients. However, the number of imputed datasets doesn't seem to matter, since there are only trivial differences in coefficients when there are 5 and 10 datasets.

```{r robust-compare-imputations, message=FALSE, warning=FALSE, cache=TRUE}
mods.robust.check.m.next_year.raw <- df.country.aid.demean.next_year.all %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total,
                                              "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total,
                                          "total.oda_log_next_year"))

# Get model details and parameters
mods.robust.check.m.next_year <- mods.robust.check.m.next_year.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int=TRUE),
         augment = model %>% map(broom::augment))

# Meld the imputed models
mods.robust.check.m.next_year.melded.original <- mods.robust.check.m.next_year %>%
  filter(m == "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.m5 <- mods.robust.check.m.next_year %>%
  filter(m %in% paste0("imp", 1:5)) %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.m10 <- mods.robust.check.m.next_year %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.all <- bind_rows(
  mods.robust.check.m.next_year.melded.original,
  mods.robust.check.m.next_year.melded.m5,
  mods.robust.check.m.next_year.melded.m10
) %>%
  mutate(imputations = data %>% map_dbl(~ nrow(.)),
         model.name = paste(model.name, imputations, sep="_"))
```

```{r tbl-show-imputations, results="asis"}
stargazer.fake(mods.robust.check.m.next_year.melded.all)
```

### Longer lags

Looking at aid 2 years and 5 years after the change in anti-NGO legislation shows similar trends to 1 year after.

```{r h1-models-2, warning=FALSE, message=FALSE, cache=TRUE}
mods.h1.after_2.raw <- df.country.aid.demean.after_2.impute %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total,
                                              "total.oda_log_next_year"),
         mod.h1.barriers.new = data %>% map(mod.h1.barriers.new,
                                            "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total,
                                          "total.oda_log_next_year"),
         mod.h1.type.new = data %>% map(mod.h1.type.new,
                                        "total.oda_log_next_year"),
         mod.h1.csre = data %>% map(mod.h1.csre,
                                    "total.oda_log_next_year"))

# Get model details and parameters
mods.h1.after_2 <- mods.h1.after_2.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int=TRUE),
         augment = model %>% map(broom::augment))

# Meld the imputed models
mods.h1.after_2.melded <- mods.h1.after_2 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

```{r h1-models-5, warning=FALSE, message=FALSE, cache=TRUE}
mods.h1.after_5.raw <- df.country.aid.demean.after_5.impute %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total,
                                              "total.oda_log_next_year"),
         mod.h1.barriers.new = data %>% map(mod.h1.barriers.new,
                                            "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total,
                                          "total.oda_log_next_year"),
         mod.h1.type.new = data %>% map(mod.h1.type.new,
                                        "total.oda_log_next_year"),
         mod.h1.csre = data %>% map(mod.h1.csre,
                                    "total.oda_log_next_year"))

# Get model details and parameters
mods.h1.after_5 <- mods.h1.after_5.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int=TRUE),
         augment = model %>% map(broom::augment))

# Meld the imputed models
mods.h1.after_5.melded <- mods.h1.after_5 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

#### Effect on ODA after 2 years

```{r h1-melded-table-2, results="asis", warning=FALSE}
stargazer.fake(mods.h1.after_2.melded)
```

#### Effect on ODA after 5 years

```{r h1-melded-table-5, results="asis", warning=FALSE}
stargazer.fake(mods.h1.after_5.melded)
```
