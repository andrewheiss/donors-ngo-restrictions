---
title: "Models"
author: "Suparna Chaudhry and Andrew Heiss"
date: "`r format(Sys.time(), '%B %e, %Y')`"
output: 
  html_document: 
    code_folding: hide
    css: ../html/fixes.css
    fig_height: 3.5
    fig_width: 5
    highlight: pygments
    includes:
      after_body: ../html/add_home_link.html
    theme: spacelab
    toc: yes
    toc_depth: 4
    toc_float: yes
---

```{r load-libraries, message=FALSE}
knitr::opts_chunk$set(cache=FALSE, fig.retina=2,
                      tidy.opts=list(width.cutoff=120),  # For code
                      options(width=120))  # For output

library(tidyverse)
library(stringr)
library(forcats)
library(stargazer)
library(lme4)
library(modelr)
library(broom)

source(file.path(PROJHOME, "lib", "graphics.R"))
source(file.path(PROJHOME, "lib", "pandoc.R"))
source(file.path(PROJHOME, "lib", "bayes.R"))

source(file.path(PROJHOME, "Analysis", "robustness_models_definitions.R"))
source(file.path(PROJHOME, "Analysis", "h1_model_definitions.R"))

my.seed <- 1234
set.seed(my.seed)

run.rstan <- FALSE
```

```{r load-data, cache=TRUE, message=FALSE}
df.country.aid <- readRDS(file.path(PROJHOME, "Data", "data_clean",
                                "df_country_aid_no_imputation.rds"))

df.country.aid.impute <- readRDS(file.path(PROJHOME, "Data", "data_clean",
                                           "df_country_aid_imputation.rds"))

df.country.aid.impute.m10 <- readRDS(file.path(PROJHOME, "Data", "data_clean",
                                               "df_country_aid_imputation_m10.rds"))

dcjw.questions.clean <- read_csv(file.path(PROJHOME, "Data", "data_clean",
                                           "dcjw_questions.csv"))
dcjw.responses.clean <- read_csv(file.path(PROJHOME, "Data", "data_clean",
                                           "dcjw_responses.csv"))

# Load clean coefficient names and append "within" and "between" to them,
# resulting in a giant table of possible coefficient names
coef.names <- read_csv(file.path(PROJHOME, "Data", "data_clean",
                                 "coef_names.csv"))

coef.names.within <- coef.names %>%
  mutate(term = paste0(term, "_within"),
         term_plot = paste0(term_clean, "\n(within)"),
         term_clean = paste0(term_clean, "~within~"))

coef.names.between <- coef.names %>%
  mutate(term = paste0(term, "_between"),
         term_plot = paste0(term_clean, "\n(between)"),
         term_clean = paste0(term_clean, "~between~"))

coef.names.all <- bind_rows(coef.names, coef.names.within, coef.names.between) %>%
  mutate(term_plot = ifelse(is.na(term_plot), term_clean, term_plot))


# Combine original data and imputed data so calculations can happen at the same time
df.country.aid.both <- bind_rows(df.country.aid, df.country.aid.impute)

# Combine m=10 imputed data too since we use it in some robustness checks.
# Imputations 6-10 are later removed
df.country.aid.all <- bind_rows(df.country.aid, df.country.aid.impute.m10)

# All the missing values have been taken care of, but final years for leaded
# variables *are* still missing (i.e. there's no aid data for 2014, so
# total.oda_log_next_year will be NA in 2013). For this fancy random effects
# regression to work, the demeaned variables have to be based on the means of
# all rows included in the regression, so they can't include rows that are
# dropped because of missingness. This means we have to make separate demeaned
# datasets for *_after_2 and *_after_5, but ¯\_(ツ)_/¯
df.country.aid.demean.next_year.all <- df.country.aid.all %>%
  filter(!is.na(total.oda_log_next_year)) %>%
  group_by(m, cowcode) %>%
  mutate_at(vars(barriers.total, advocacy, entry, funding, 
                 polity, gdp.capita_log, gdp.capita, trade.pct.gdp, corruption, csre,
                 total.oda_log),
            funs(between = mean(., na.rm=TRUE),  # meaned
                 within = . - mean(., na.rm=TRUE))) %>%  # demeaned
  ungroup()

# Divide demeaned data into separate data frames: original, imputed (m=5), and imputed (m=10)
df.country.aid.demean.next_year.both <- 
  filter(df.country.aid.demean.next_year.all, !(m %in% paste0("imp", 6:10)))

df.country.aid.demean.next_year <- 
  filter(df.country.aid.demean.next_year.all, m == "original")

df.country.aid.demean.next_year.impute <- 
  filter(df.country.aid.demean.next_year.all, 
         m != "original", !(m %in% paste0("imp", 6:10)))

df.country.aid.demean.next_year.impute.m10 <- 
  filter(df.country.aid.demean.next_year.all, m != "original")

# Demean data with total.oda_log leaded by 2 years and 5 years
# After 2 years
df.country.aid.demean.after_2.both <- df.country.aid.both %>%
  filter(!is.na(total.oda_log_after_2)) %>%
  group_by(m, cowcode) %>%
  mutate_at(vars(barriers.total, advocacy, entry, funding, 
                 polity, gdp.capita_log, gdp.capita, trade.pct.gdp, corruption, csre,
                 total.oda_log),
            funs(between = mean(., na.rm=TRUE),  # meaned
                 within = . - mean(., na.rm=TRUE))) %>%  # demeaned
  ungroup()

df.country.aid.demean.after_2 <- 
  filter(df.country.aid.demean.after_2.both, m == "original")

df.country.aid.demean.after_2.impute <- 
  filter(df.country.aid.demean.after_2.both, m != "original")

# After 5 years
df.country.aid.demean.after_5.both <- df.country.aid.both %>%
  filter(!is.na(total.oda_log_after_5)) %>%
  group_by(m, cowcode) %>%
  mutate_at(vars(barriers.total, advocacy, entry, funding, 
                 polity, gdp.capita_log, gdp.capita, trade.pct.gdp, corruption, csre,
                 total.oda_log),
            funs(between = mean(., na.rm=TRUE),  # meaned
                 within = . - mean(., na.rm=TRUE))) %>%  # demeaned
  ungroup()

df.country.aid.demean.after_5 <- 
  filter(df.country.aid.demean.after_5.both, m == "original")

df.country.aid.demean.after_5.impute <- 
  filter(df.country.aid.demean.after_5.both, m != "original")
```

```{r helpful-functions}
stars <- function(p) {
  out <- symnum(p, cutpoints=c(0, 0.01, 0.05, 0.1, 1),
                symbols=c("***", "**", "*", ""))
  as.character(out)
}

fixed.digits <- function(x, n=2) {
  formatC(x, digits=n, format="f")
}

# Inverse logit, with the ability to account for adjustments
# via http://stackoverflow.com/a/23845527/120898
inv.logit <- function(f, a) {
  a <- (1 - 2 * a)
  (a * (1 + exp(f)) + (exp(f) - 1)) / (2 * a * (1 + exp(f)))
}

# Take apart the pieces of a random effects formula and rebuild it
build.formula <- function(DV, IVs) {
  terms.all <- attr(terms(IVs), "term.labels")
  terms.fixed <- terms.all[!stringr::str_detect(terms.all, "\\|")]
  terms.rand <- sapply(findbars(formula(IVs)),function(x) paste0("(", deparse(x), ")"))
  
  reformulate(c(terms.fixed, terms.rand), response=DV)
}

# Meld a bunch of imputed models
meld.imputed.models <- function(model.data) {
  models.df <- model.data$glance[[1]]$df.residual
  
  models.tidy <- model.data %>%
    select(tidy) %>%
    unnest(.id="imputation")
  
  just.estimates <- models.tidy %>% 
    filter(group == "fixed") %>%
    select(imputation, term, estimate) %>%
    spread(term, estimate) %>%
    select(-imputation)
  
  just.ses <- models.tidy %>%
    filter(group == "fixed") %>%
    select(imputation, term, std.error) %>%
    spread(term, std.error) %>%
    select(-imputation)

  # If no imputed data was passed in, use the actual estimates and SEs
  if (nrow(just.estimates) > 1) {
    melded <- Amelia::mi.meld(just.estimates, just.ses)
  } else {
    melded <- list(q.mi = just.estimates, se.mi = just.ses)
  }

  melded.tidy <- as.data.frame(cbind(t(melded$q.mi), 
                                     t(melded$se.mi))) %>%
    magrittr::set_colnames(c("estimate", "std.error")) %>%
    mutate(term = rownames(.)) %>%
    select(term, everything()) %>%
    mutate(statistic = estimate / std.error,
           conf.low = estimate + std.error * qt(0.025, models.df),
           conf.high = estimate + std.error * qt(0.975, models.df),
           p.value = 2 * pt(abs(statistic), models.df, lower.tail=FALSE),
           stars = stars(p.value))  
  melded.tidy
}

# Expects a data frame with a column named tidy.melded and a row for model
# names. Term names are based on the first model in the data column for each
# row, and are filtered through stargazer to get the correct row order.
stargazer.fake <- function(df) {
  # Create a blank row with a bolded row name
  header.row <- function(header) {
    data_frame(term = paste0("**", header, "**"), 
               models = df$model.name, value = "") %>%
    spread(models, value)
  }
  
  coef.order.models <- df %>%
    # Select just the first row of each model
    unnest(data) %>%
    # Sometimes there are duplicate column names
    # magrittr::set_colnames(make.unique(colnames(.))) %>%
    # Keep order of model.name
    mutate(model.name = ordered(fct_inorder(model.name))) %>%
    group_by(model.name) %>%
    slice(1) %>% ungroup() %>%
    select(model) %>% as.list()
  
  # Use stargazer to get the coefficient order. I tried recreating stargazer's
  # coefficient ordering algorithm but it's way too complicated. So instead, we
  # cheat and let stargazer do the heavy lifting, save the output to a string,
  # and then extract the coefficient names with str_extract. Super super hacky,
  # but it works.
  #
  # See http://stackoverflow.com/a/41801861/120898
  capture.output({
    stargazer.coefs <- stargazer::stargazer(coef.order.models, 
                                            type="text", table.layout="t")
  }, file="/dev/null")
  
  coef.order <- setdiff(stringr::str_extract(stargazer.coefs, "^[\\w\\.]*"), c(""))
  
  # Fixed parts
  fixed.coefs <- df %>%
    unnest(tidy.melded) %>%
    mutate(fancy = paste0(fixed.digits(estimate, 3),
                          stars, "\\ \n(",
                          fixed.digits(std.error, 3),
                          ")")) %>%
    select(model.name, term, fancy) %>%
    spread(model.name, fancy, fill="") %>%
    # Clean up term names
    mutate(term = stringr::str_replace(term, "TRUE$|FALSE$", ""),
           term = recode(term, `(Intercept)` = "Constant")) %>%
    # Use stargazer's coefficient order
    mutate(term = factor(term, levels=coef.order, ordered=TRUE)) %>%
    arrange(term) %>%
    mutate(term = as.character(term)) %>%
    left_join(coef.names.all, by="term") %>%
    mutate(term_clean = ifelse(term == "Constant", "Constant", term_clean)) %>%
    select(-term) %>% rename(term = term_clean) %>%
    select_(.dots = c("term", df$model.name))
  
  # Random parts
  random.coef.order.raw <- df %>%
    unnest(data) %>%
    # unnest(data) %>% magrittr::set_colnames(make.unique(colnames(.))) %>%
    select(model.name, model) %>%
    mutate(ranef = model %>% map(~ as.data.frame(VarCorr(.)))) %>%
    unnest(ranef)
  random.coef.order <- c(setdiff(unique(random.coef.order.raw$grp), "Residual"), "Residual")
  
  random.coefs <- df %>%
    unnest(data) %>%
    unnest(tidy) %>%
    filter(group != "fixed") %>%
    rename(term.raw = term, term = group) %>%
    group_by(model.name, term) %>%
    summarise(avg.random.sd = mean(estimate),
              sd.random.sd = sd(estimate)) %>%
    mutate(fancy = paste0(fixed.digits(avg.random.sd, 3),
                          "\\ \n(",
                          ifelse(is.na(sd.random.sd), "NA", fixed.digits(sd.random.sd, 3)),
                          ")")) %>%
    select(model.name, term, fancy) %>%
    spread(model.name, fancy, fill="") %>%
    mutate(term = factor(term, levels=random.coef.order, ordered=TRUE)) %>%
    arrange(term) %>% mutate(term = as.character(term)) %>%
    left_join(coef.names.all, by="term") %>%
    mutate(term_clean = ifelse(term == "Residual", 
                               "Residual random error ($\\sigma$)", term_clean)) %>%
    select(-term) %>% select(term=term_clean, everything())

  # Create the bottom half of the table
  # Calculate the average log likelihood for all imputed models
  avg.loglik <- df %>%
    unnest(data) %>% unnest(glance) %>%
    group_by(model.name) %>%
    summarise(avg.loglik = as.character(round(mean(logLik), 2))) %>%
    mutate(term = "Log likelihood (mean)") %>%
    spread(model.name, avg.loglik)

  # Imputation frames
  n.obs <- df %>%
    unnest(data) %>%
    mutate(n = model %>% map_int(~ nrow(.@frame))) %>%
    select(model.name, n) %>%
    group_by(model.name) %>% slice(1) %>% ungroup() %>%
    mutate(term = "Observations",
           n = scales::comma(n)) %>%
    spread(model.name, n)
  
  n.m <- df %>%
    mutate(m.new = data %>% map_int(~ nrow(.))) %>%
    select(model.name, m.new) %>% 
    mutate(m.new = ifelse(m.new == 1, 0, m.new),
           m.new = as.character(m.new)) %>%
    mutate(term = "Imputed datasets (*m*)") %>%
    spread(model.name, m.new)

  bottom.details <- bind_rows(n.obs, avg.loglik, n.m)

  nice.top.bottom <- bind_rows(header.row("Fixed part"), fixed.coefs, 
                               header.row("Random part"), random.coefs,
                               header.row("Model details"), bottom.details) %>%
    select_(.dots = c("term", df$model.name))
  
  # Make column names (1), (2), etc.
  # TODO: Allow for custom column names
  colnames(nice.top.bottom) <- c("", paste0("(", 1:length(df$model.name), ")"))
  
  # All columns are centered except the first
  # TODO: MAYBE: Let this be user configurable
  table.align <- paste0(c("l", rep("c", length(df$model.name))), collapse="")
  
  pandoc.table(nice.top.bottom, keep.line.breaks=TRUE, justify=table.align)
}
```

## General model specifications and controls

We use a standard set of controls in each model ([explained in more detail here](../Data/get_merge_data.html#other_controls_and_alternative_hypotheses)):

- Democracy: `polity`
- Wealth: `gdp.capita_log` (logged so it's on the same scale as the other variables) 
- Government capacity: `corruption`
- Bad stuff: `internal.conflict.past.5` and `natural_disaster.occurrence`

Following [Bell and Jones (2015)](http://dx.doi.org/10.1017/psrm.2014.7), we use crossed random effects for country and year and use a combination of meaned and demeaned versions of each continuous variable to estimate both the within and between effects of each variable. 

$$ y_{i, t + 1} = \beta_0 + \beta_1 (x_{it} - \bar{x}_i) + \beta_2 \bar{x}_i + \ldots $$

This approach has multiple benefits. The coefficients for the demeaned variables are roughly equivalent to their corresponding coefficients in a fixed effects model, but a fixed effects model assumes that the between effect (captured by the mean variables) is 0, which is not the case. A random effects model specified in this manner is more interpretable, as it clearly separates the within and between effects (again, within = demeaned, between = mean).

Here's proof of how it works in some simple models. Model 1 is a basic OLS with country fixed effects. Model 2 is a basic OLS with country random effects, but potentially misspecified, since the between and within effects are conflated. Model 3 is a basic OLS with country random effects specified with between (mean; $\bar{x}_i$) and within (demeaned; $x_{it} - \bar{x}_i$) coefficients. The demeaned/within coefficients in Model 3 are identical to the fixed effects coefficients in Model 1. If rows had been dropped because of listwise deletion (like, if there were missing values in one of independent variables), the coefficients would be slightly off, since the demeaned values would have been based on group means that included the values that were dropped (e.g. all 2013 rows are dropped because of lags, but the group means included 2013). This isn't  a problem in these reduced models, but that's one reason we impute all the data—we need the data to be as complete as possible to get the most accurate random effects.

```{r fixed-random-example, results="asis"}
mod.test.fe <- lm(total.oda_log_next_year ~ 
                    barriers.total + polity + gdp.capita_log + 
                    as.factor(cowcode),
                  data=df.country.aid.demean.next_year)

mod.test.re <- lmer(total.oda_log_next_year ~ 
                    barriers.total + polity + gdp.capita_log + 
                    (1 | cowcode),
                  data=df.country.aid.demean.next_year)

mod.test.re.fancy <- lmer(total.oda_log_next_year ~ 
                            barriers.total_between + barriers.total_within +
                            polity_between + polity_within + 
                            gdp.capita_log_between + gdp.capita_log_within +
                            (1 | cowcode),
                          data=df.country.aid.demean.next_year)

stargazer(mod.test.fe, mod.test.re, mod.test.re.fancy,
          type="html", omit="factor", 
          add.lines=list(c("Country effects",
                           c("Fixed", "Random", "Random"))),
          keep.stat=c("n"))
```

\
All of the models we run use imputed data ($m = 5$) with crossed year and country random effects. Most explanatory and control variables are included in their meaned and demeaned forms, except for any indicator variables (since you can't really average binary data). Additionally, we include the regular form of the current year's ODA to account for temporal autocorrelation in aid. We do not split current ODA into within and between versions so that mathematically it can be subtracted out of the next year's ODA in the dependent variable. Other mixed models functions like `nlme::lme()` allow you to define autoregressive correlation structures, but `lme4::lmer()` doesn't, so we account for time with this differenced approach instead. It's not perfect, but it works:

```{r show.acf.lags}
mod.test.no.oda <- lmer(total.oda_log_next_year ~ 
                          barriers.total_between + barriers.total_within +
                          polity_between + polity_within + 
                          gdp.capita_log_between + gdp.capita_log_within +
                          (1 | cowcode) + (1 | year),
                        data=filter(df.country.aid.demean.next_year.impute,
                                    m == "imp1"))

mod.test.oda.split <- lmer(total.oda_log_next_year ~ 
                             barriers.total_between + barriers.total_within +
                             polity_between + polity_within + 
                             total.oda_log_between + total.oda_log_within +
                             gdp.capita_log_between + gdp.capita_log_within +
                             (1 | cowcode) + (1 | year),
                           data=filter(df.country.aid.demean.next_year.impute,
                                       m == "imp1"))

mod.test.oda.nosplit <- lmer(total.oda_log_next_year ~ 
                               barriers.total_between + barriers.total_within +
                               polity_between + polity_within + 
                               total.oda_log +
                               gdp.capita_log_between + gdp.capita_log_within +
                               (1 | cowcode) + (1 | year),
                             data=filter(df.country.aid.demean.next_year.impute,
                                         m == "imp1"))

resid.no.oda <- acf(residuals(mod.test.no.oda), plot=FALSE)
resid.oda <- acf(residuals(mod.test.oda.nosplit), plot=FALSE)

ci.line <- qnorm((1 + 0.95) / 2) / sqrt(resid.no.oda$n.used)

acf.plot.data <- bind_rows(
  data_frame(Lag = resid.no.oda$lag[,,1], ACF = resid.no.oda$acf[,,1], 
             model = "No ODA"),
  data_frame(Lag = resid.oda$lag[,,1], ACF = resid.oda$acf[,,1], 
             model = "Current year’s ODA")
)

ggplot(acf.plot.data, aes(x=Lag, y=ACF, fill=model)) +
  geom_bar(stat="identity", position=position_dodge(width=1), width=0.5) +
  geom_hline(yintercept=0, size=1) +
  geom_hline(yintercept=c(ci.line, -ci.line), size=0.5, linetype="dashed") +
  guides(fill=guide_legend(title=NULL)) +
  theme_donors()
```

Not splitting current ODA into within and between also fixes another sticky mathematical issue. When the models are run with within and current ODA, the $\sigma$ value for within-country variability becomes 0 for whatever reason (maybe it swallows up too much country level variability?). When $\sigma = 0$, the between-group variability is too small to fully account for between effects, resulting in a "degenerate model" (see [pages 10–11 here](http://lme4.r-forge.r-project.org/lMMwR/lrgprt.pdf)) and influencing the coefficients in weird ways. See below, where Model 1 uses the split current ODA and Model 2 doesn't: $\sigma$ in Model 2 exists and the coefficients are better estimated.

```{r h1-table-results, results="asis"}
stargazer(mod.test.oda.split, mod.test.oda.nosplit,
          type="html", keep.stat=c("n"))

bind_rows(
  as.data.frame(VarCorr(mod.test.oda.split)) %>% mutate(model="(1)"),
  as.data.frame(VarCorr(mod.test.oda.nosplit)) %>% mutate(model="(2)")
) %>% 
  mutate(grp = ordered(fct_inorder(grp))) %>%
  select(`Random variable` = grp, sdcor, model) %>%
  spread(model, sdcor) %>% pandoc.table()
```

---

## H~1~: Donors reduce aid in response to legislation

> **H~1~**: In response to restrictive NGO legislation, bilateral, multilateral, and private donors may reduce their aid to repressive countries.

$$ln( \text{ODA} )_{i, t+1} = \text{NGO legislation}_{it} + \text{controls}_{it}$$

Our dependent variable for this hypothesis is the log of ODA (constant 2011 dollars), leaded by one year so we don't have to lag every other independent variable. As a robustness check, we also include models with log ODA leaded by 2 years and 5 years to account the implementation period following the passage of a law.

We look at NGO legislation in a few different ways:

- `barriers.total`: Number of anti-NGO legal barriers in a country-year
- `barriers.total_new`: Indicator marking if a new anti-NGO barrier was passed in a country year
- `advocacy + entry + funding`: Number of anti-NGO legal barriers by type of barrier
- `advocacy_new + entry_new + funding_new`: Indicators marking new type of barrier
- `csre`: Civil society regulatory environment index (CSRE), ranging from roughly -4 to 4 (higher values = better civil society regulations)

```{r h1-models-1, warning=FALSE, message=FALSE, cache=TRUE}
# Run models on each of the datasets (original and imputed) and save in a big data frame
mods.h1.next_year.raw <- df.country.aid.demean.next_year.both %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total,
                                              "total.oda_log_next_year"),
         mod.h1.barriers.new = data %>% map(mod.h1.barriers.new,
                                            "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total,
                                          "total.oda_log_next_year"),
         mod.h1.type.new = data %>% map(mod.h1.type.new,
                                        "total.oda_log_next_year"),
         mod.h1.csre = data %>% map(mod.h1.csre,
                                    "total.oda_log_next_year"))

# Get model details and parameters
mods.h1.next_year <- mods.h1.next_year.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int=TRUE),
         augment = model %>% map(broom::augment))

# Meld the imputed models
mods.h1.next_year.melded <- mods.h1.next_year %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

```{r h1-models-bayes-1, warning=FALSE, message=FALSE}
if (run.rstan) {
  source(file.path(PROJHOME, "Analysis", "h1_model_definitions_bayes.R"))
  
  mods.h1.next_year.raw.bayes <- df.country.aid.demean.next_year %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total.bayes,
                                              "total.oda_log_next_year"),
         mod.h1.barriers.new = data %>% map(mod.h1.barriers.new.bayes,
                                            "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total.bayes,
                                          "total.oda_log_next_year"),
         mod.h1.type.new = data %>% map(mod.h1.type.new.bayes,
                                        "total.oda_log_next_year"),
         mod.h1.csre = data %>% map(mod.h1.csre.bayes,
                                    "total.oda_log_next_year"))
}
```

### Results

```{r plot-h1-coefs, fig.width=5, fig.height=4}
vars.to.plot <- c("barriers.total_within", "barriers.total_between",
                  "barriers.total_new",
                  "advocacy_within", "advocacy_between", 
                  "entry_within", "entry_between", 
                  "funding_within", "funding_between",
                  "advocacy_new", "entry_new", "funding_new",
                  "csre_within", "csre_between")

coefs.raw <- mods.h1.next_year.melded %>%
  unnest(tidy.melded) %>%
  filter(term != "(Intercept)",
         term %in% vars.to.plot) %>%
  left_join(coef.names.all, by="term") %>%
  mutate(term = factor(term, levels=vars.to.plot, ordered=TRUE)) %>%
  arrange(desc(term)) %>%
  mutate(term_plot = ordered(fct_inorder(term_plot))) %>%
  mutate(coef.type = case_when(
    str_detect(.$term, "_within") ~ "Within",
    str_detect(.$term, "_between") ~ "Between",
    TRUE ~ "Not split"
  )) %>% 
  mutate(coef.type = factor(coef.type, levels=c("Within", "Between", "Not split"),
                            ordered=TRUE))

ggplot(coefs.raw, aes(y=term_plot, x=estimate, colour=coef.type)) + 
  geom_vline(xintercept=0, colour="grey50", size=1) + 
  geom_pointrangeh(aes(xmin=conf.low, xmax=conf.high), size=.5) + 
  labs(x="Estimate", y=NULL) +
  guides(color=guide_legend(title=NULL)) +
  theme_donors()
```

```{r h1-melded-table-1, results="asis", warning=FALSE}
stargazer.fake(mods.h1.next_year.melded)
```

### Model diagnostics

Country intercepts vary with an SD of 0.295 (etc.), year intercepts vary with an SD of 0.272 (etc.), and the SD of error not accounted for by either within-country or within-year variability is 3 (etc.)


### Predicted ODA

The total number of anti-NGO legal barriers has a significant negative effect on ODA in the following year—adding a new barrier beyond a country's average number of all time barriers is associated with a 7.4% reduction in aid in the next year (p < 0.1). This difference has substantive significant, as seen in the simulated plot below, which shows 50 model simulations from each of the 5 imputed datasets across a range of differences from the average number of NGO laws in an average country (with all independent variables held at their mean or modal values). (And amazingly, because of math, the slope of the thick line below is essentially the coefficient from the model, 0.7ish.)

```{r h1-simulate-total, warning=FALSE, fig.width=6}
# Make predictions inside each dataset, then average them. So says Gary King:
# https://lists.gking.harvard.edu/pipermail/gov2001/2003-May/005327.html
simulate.predictions.barriers <- function(x) {
  new.data <- x@frame %>%
    select(-c(barriers.total_within, year, cowcode)) %>%
    summarise_all(typical) %>%
    mutate(id = 1,
           total.oda_log_next_year = NA) %>%
    right_join(expand.grid(barriers.total_within = seq(-5, 5, 0.5),
                           cowcode = 1000:1050,
                           year = 1981:2012,
                           id = 1), by="id") %>% select(-id)
  
  df.simulated.all <- tribble(
    ~id, ~data,
    # Uncomment to include predictions of original data
    # "original", model.to.use@frame,
    "hypothetical", new.data
  ) %>%
    # Use simulate() instead of predict() to use the random effects in the predictions
    # https://tmalsburg.github.io/blog/predict-vs-simulate-in-lme4/
    mutate(simulated = data %>% 
             map(~ simulate(x, nsim=1, seed=1, 
                            newdata=select(.x, -total.oda_log_next_year), 
                            re.form=NA, allow.new.levels=TRUE))) %>%
    unnest()
  
  return(df.simulated.all)
}

simulated.h1.barriers.total <- mods.h1.next_year.melded %>%
  filter(model.name == "mod.h1.barriers.total") %>%
  unnest(data) %>%
  mutate(simulated = model %>% map(~ simulate.predictions.barriers(.))) %>%
  unnest(simulated)

df.plot.data <- simulated.h1.barriers.total %>%
  group_by(id, m, cowcode, barriers.total_within) %>%
  summarise_at(vars(starts_with("sim")), funs(avg = mean(.))) %>%
  ungroup() %>%
  gather(key, value, -c(id, m, cowcode, barriers.total_within))

df.plot.data.mean <- df.plot.data %>%
  group_by(barriers.total_within) %>%
  summarise(value = mean(value)) %>%
  mutate(value.exp = expm1(value)) %>%
  mutate(cowcode=1)  # Fake country so the line plots

fig.simulated.h1.barriers <- ggplot(df.plot.data, aes(x=barriers.total_within, 
                                                     y=expm1(value), group=cowcode)) + 
  geom_vline(xintercept=0, size=0.5) +
  geom_smooth(method="lm", size=0.1, alpha=0.1, colour="#DB9E36") +
  geom_smooth(data=df.plot.data.mean, size=1.5, method="lm", colour="#BD4932") +
  labs(x="Difference from average number of anti-NGO barriers in country\n(within coefficient)",
       y="Simulated ODA in the following year") +
  scale_y_continuous(labels=scales::dollar, trans=scales::log1p_trans()) +
  theme_donors()
```

The negative effect of anti-NGO barriers appears to be driven primarily by barriers to advocacy, such as laws restricting NGOs from engaging in political activities or government intimidation or dissolution of NGOs involved in politics. Adding a new barrier to advocacy above a country's average number of anti-advocacy laws is associated with a 46% drop in ODA in the following year (p < 0.1). Looking at the imposition of a new law rather than a change in the number of laws also yields a significant effect—a new anti-advocacy law is associated with a 100% drop in ODA in the following year. Notably, adding additional barriers to entry or funding has no noticeable effect on a country's aid in the following year. Additionally, the overall civil society regulatory environment in a country is also not associated with changes in aid. It appears that donors are more responsive to direct political intimidation and restriction than more benign bureaucratic legal barriers.

`TODO`: Discuss the between coefficients; discuss aid leaded by 2 and 5 years

```{r h1-simulate-individual, warning=FALSE}
simulate.predictions.indiv.barriers <- function(x) {
  hypothetical.bounds <- x@frame %>%
    select(advocacy_within, entry_within, funding_within) %>%
    summarise_all(funs(min, max)) %>%
    gather(key, value) %>%
    mutate(value = round(value, 0)) %>%
    # Have to separate on _m because of multiple _s, then re-add the m
    separate(key, into=c("term", "variable"), sep="_m") %>%
    mutate(variable = paste0("m", variable)) %>%
    spread(variable, value)
  
  new.data.hypothetical.nested <- hypothetical.bounds %>%
    nest(-term) %>%
    mutate(newdata = map2(.x=data, .y=term,
                          ~ expand.grid(term = seq(.x$min, .x$max, by=0.5),
                                        cowcode = 1000:1050,
                                        year = 1981:2012,
                                        id = 1) %>%
                            # Rename the term column to the actual term name
                            magrittr::set_colnames(c(.y, colnames(.)[-1]))))
  
  new.data.hypothetical <- as_tibble(bind_rows(new.data.hypothetical.nested$newdata)) %>%
    mutate_at(vars(contains("within")), funs(ifelse(is.na(.), 0, .)))
  
  new.data <- x@frame %>%
    select(-c(advocacy_within, entry_within, funding_within, year, cowcode)) %>%
    summarise_all(typical) %>%
    mutate(id = 1,
           total.oda_log_next_year = NA) %>%
    right_join(new.data.hypothetical, by="id") %>% select(-id)
  
  df.simulated.all <- tribble(
    ~id, ~data,
    # Uncomment to include predictions of original data
    # "original", model.to.use@frame,
    "hypothetical", new.data
  ) %>%
    # Use simulate() instead of predict() to use the random effects in the predictions
    # https://tmalsburg.github.io/blog/predict-vs-simulate-in-lme4/
    mutate(simulated = data %>% 
             map(~ simulate(x, nsim=1, seed=1, 
                            newdata=select(.x, -total.oda_log_next_year), 
                            re.form=NA, allow.new.levels=TRUE))) %>%
    unnest()
  
  return(df.simulated.all)
}

barriers.indiv.clean.names <- tribble(
  ~barrier, ~barrier.clean,
  "advocacy_within", "Barriers to advocacy",
  "entry_within", "Barriers to entry",
  "funding_within", "Barriers to funding"
)

simulated.h1.barriers.indiv <- mods.h1.next_year.melded %>%
  filter(model.name == "mod.h1.type.total") %>%
  unnest(data) %>%
  mutate(simulated = model %>% map(~ simulate.predictions.indiv.barriers(.))) %>%
  unnest(simulated) %>%
  gather(barrier, barrier.value, c(advocacy_within, entry_within, funding_within))

df.plot.data.indiv <- simulated.h1.barriers.indiv %>%
  group_by(id, m, cowcode, barrier, barrier.value) %>%
  summarise_at(vars(starts_with("sim")), funs(avg = mean(.))) %>%
  ungroup() %>%
  gather(key, value, -c(id, m, cowcode, barrier, barrier.value)) %>%
  left_join(barriers.indiv.clean.names, by="barrier")

df.plot.data.mean.indiv <- df.plot.data.indiv %>%
  group_by(barrier, barrier.value) %>%
  summarise(value = mean(value)) %>%
  mutate(value.exp = expm1(value)) %>%
  mutate(cowcode=1) %>%  # Fake country so the line plots
  left_join(barriers.indiv.clean.names, by="barrier")

# fig.simulated.h1.barriers.indiv <- ggplot(df.plot.data.indiv, 
#                                           aes(x=barrier.value, y=expm1(value), 
#                                               group=cowcode)) + 
#   geom_vline(xintercept=0, size=0.5) +
#   geom_smooth(method="lm", size=0.1, alpha=0.1, colour="#DB9E36") +
#   geom_smooth(data=df.plot.data.mean.indiv, size=1.5, method="lm", colour="#BD4932") +
#   labs(x="Difference from average number of anti-NGO barriers in country\n(within coefficients)",
#        y="Simulated ODA in the following year") +
#   scale_y_continuous(labels=scales::dollar, trans=scales::log1p_trans()) +
#   facet_wrap(~ barrier.clean, scales="free_x") +
#   theme_donors()
```

```{r h1-simulate-both, warning=FALSE, fig.width=6.5, fig.height=4}
# Combine the two plot data frames
df.plot.data.both <- df.plot.data %>%
  mutate(barrier = "barriers.total_within", barrier.clean = "Total barriers") %>%
  rename(barrier.value = barriers.total_within) %>%
  bind_rows(df.plot.data.indiv) %>%
  mutate(barrier.clean = ordered(fct_inorder(barrier.clean)),
         highlight = ifelse(barrier.clean == "Total barriers", TRUE, FALSE))

df.plot.data.mean.both <- df.plot.data.mean %>%
  mutate(barrier = "barriers.total_within", barrier.clean = "Total barriers") %>%
  rename(barrier.value = barriers.total_within) %>%
  bind_rows(df.plot.data.mean.indiv) %>%
  mutate(barrier.clean = ordered(fct_inorder(barrier.clean)))

# Create data frame for highlighting the total panel
df.panel.highlight <- df.plot.data.both %>%
  distinct(barrier.clean, highlight)

fig.simulated.h1.barriers.both <- ggplot(df.plot.data.both, 
                                         aes(x=barrier.value, y=expm1(value), 
                                             group=cowcode)) + 
  geom_rect(data=df.panel.highlight, 
            aes(fill=highlight, x=NULL, y=NULL, group=NULL),
            xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf, alpha=0.15) +
  geom_vline(xintercept=0, size=0.5) +
  geom_smooth(method="lm", size=0.1, alpha=0.1, colour="#DB9E36") +
  geom_smooth(data=df.plot.data.mean.both, size=1.5, method="lm", colour="#BD4932") +
  labs(x="Difference from average number of anti-NGO barriers in country\n(within coefficients)",
       y="Simulated ODA in the following year") +
  scale_y_continuous(labels=scales::dollar, trans=scales::log1p_trans()) +
  scale_fill_manual(values=c(NA, "grey50"), guide=FALSE) +
  facet_wrap(~ barrier.clean, scales="free_x") +
  theme_donors()

fig.display.both <- fig.simulated.h1.barriers.both + 
  labs(title="Donors reduce aid more in response to\nadditional advocacy-focused anti-NGO laws",
       subtitle="Simulated foreign aid (ODA) across range of differences from the average number of\nanti-NGO laws in a hypothetical average country; dark line shows average of\n50 simulations across 5 imputed datasets",
       caption="Chaudhry and Heiss (2017)") + 
  theme_donors(11)

fig.simulated.h1.barriers.both
```

---

## H~2~: Donors shift aid to tamer causes

> **H~2~**: As restrictive laws against NGOs are enacted, donors start increasing funds for 'tamer' causes, and decreasing funds for politically sensitive causes.

$$\text{% contentious aid}_{i, t+1} = \text{NGO legislation}_{it} + \text{controls}_{it}$$


### Results


### Model diagnostics


### Predicted ODA


---

## H~3~: Donors shift aid to international NGOs

> **H~3~**: As restrictive laws against local NGOs increase, states should be more likely to provide aid to INGOs rather than local NGOs.

$$\text{% aid to INGOs}_{i, t+1} = \text{NGO legislation}_{it} + \text{controls}_{it}$$


### Results


### Model diagnostics


### Predicted ODA


---

## H~4~: Donors shift aid to neighboring countries

> **H~4~**: As restrictive laws against NGOs in a country are enacted, donors should be more likely to provide aid to neighboring countries.

$$ln( \text{ODA in neighboring countries} )_{i, t+1} = \text{NGO legislation}_{it} + \text{controls}_{it}$$


### Results


### Model diagnostics


### Predicted ODA


---

## H~a~: Quality of governance tempers shifts in aid

### Results


### Model diagnostics


### Predicted ODA


---

## Robustness checks

### Imputation

[As discussed over in the data cleaning file](../Data/get_merge_data.html#missingness_and_imputation), we impute data for the few variables that are missing. To show what difference imputation makes, the table below shows three pairs of models from H~1~. The first two models are run on non-imputed data (so missing observations are deleted listwise), the second two models are run on 5 sets of imputed data, and the last two models are run on 10 sets of imputed data. 

It's clear that imputation makes a substantial difference—note the big differences between coefficients. However, the number of imputed datasets doesn't seem to matter, since there are only trivial differences in coefficients when there are 5 and 10 datasets.

```{r robust-compare-imputations, message=FALSE, warning=FALSE, cache=TRUE}
mods.robust.check.m.next_year.raw <- df.country.aid.demean.next_year.all %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total,
                                              "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total,
                                          "total.oda_log_next_year"))

# Get model details and parameters
mods.robust.check.m.next_year <- mods.robust.check.m.next_year.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int=TRUE),
         augment = model %>% map(broom::augment))

# Meld the imputed models
mods.robust.check.m.next_year.melded.original <- mods.robust.check.m.next_year %>%
  filter(m == "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.m5 <- mods.robust.check.m.next_year %>%
  filter(m %in% paste0("imp", 1:5)) %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.m10 <- mods.robust.check.m.next_year %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))

mods.robust.check.m.next_year.melded.all <- bind_rows(
  mods.robust.check.m.next_year.melded.original,
  mods.robust.check.m.next_year.melded.m5,
  mods.robust.check.m.next_year.melded.m10
) %>%
  mutate(imputations = data %>% map_dbl(~ nrow(.)),
         model.name = paste(model.name, imputations, sep="_"))
```

```{r tbl-show-imputations, results="asis"}
stargazer.fake(mods.robust.check.m.next_year.melded.all)
```

### Longer lags

Looking at aid 2 years and 5 years after the change in anti-NGO legislation shows similar trends to 1 year after.

```{r h1-models-2, warning=FALSE, message=FALSE, cache=TRUE}
mods.h1.after_2.raw <- df.country.aid.demean.after_2.impute %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total,
                                              "total.oda_log_next_year"),
         mod.h1.barriers.new = data %>% map(mod.h1.barriers.new,
                                            "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total,
                                          "total.oda_log_next_year"),
         mod.h1.type.new = data %>% map(mod.h1.type.new,
                                        "total.oda_log_next_year"),
         mod.h1.csre = data %>% map(mod.h1.csre,
                                    "total.oda_log_next_year"))

# Get model details and parameters
mods.h1.after_2 <- mods.h1.after_2.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int=TRUE),
         augment = model %>% map(broom::augment))

# Meld the imputed models
mods.h1.after_2.melded <- mods.h1.after_2 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

```{r h1-models-5, warning=FALSE, message=FALSE, cache=TRUE}
mods.h1.after_5.raw <- df.country.aid.demean.after_5.impute %>%
  nest(-m) %>%
  mutate(mod.h1.barriers.total = data %>% map(mod.h1.barriers.total,
                                              "total.oda_log_next_year"),
         mod.h1.barriers.new = data %>% map(mod.h1.barriers.new,
                                            "total.oda_log_next_year"),
         mod.h1.type.total = data %>% map(mod.h1.type.total,
                                          "total.oda_log_next_year"),
         mod.h1.type.new = data %>% map(mod.h1.type.new,
                                        "total.oda_log_next_year"),
         mod.h1.csre = data %>% map(mod.h1.csre,
                                    "total.oda_log_next_year"))

# Get model details and parameters
mods.h1.after_5 <- mods.h1.after_5.raw %>%
  gather(model.name, model, -m, -data) %>%
  mutate(glance = model %>% map(broom::glance),
         tidy = model %>% map(broom::tidy, conf.int=TRUE),
         augment = model %>% map(broom::augment))

# Meld the imputed models
mods.h1.after_5.melded <- mods.h1.after_5 %>%
  filter(m != "original") %>%
  group_by(model.name) %>%
  nest() %>%
  mutate(tidy.melded = data %>% map(meld.imputed.models))
```

#### Effect on ODA after 2 years

```{r h1-melded-table-2, results="asis", warning=FALSE}
stargazer.fake(mods.h1.after_2.melded)
```

#### Effect on ODA after 5 years

```{r h1-melded-table-5, results="asis", warning=FALSE}
stargazer.fake(mods.h1.after_5.melded)
```
